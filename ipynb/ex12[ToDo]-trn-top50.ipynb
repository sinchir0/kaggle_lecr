{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2b29e0-150c-47b3-9f56-e0241255ca87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"ex12-trn-top50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd0b75a-2889-48af-b1df-a47cb38584bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OUTPUT_DIR = f\"/notebooks/kaggle_lecr/output/{NOTEBOOK_NAME}\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea3d0df-f4e8-4202-a89b-f5926005aa42",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch==1.12.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.12.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.9/site-packages (from torch==1.12.0) (4.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers==0.12.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.12.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.20.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (4.20.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (1.23.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (2022.10.31)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.20.1) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip3 install torch==1.12.0 --extra-index-url https://download.pytorch.org/whl/cu116\")\n",
    "os.system(\"pip install tokenizers==0.12.1\")\n",
    "os.system(\"pip install transformers==4.20.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09c789d-506f-4886-b7ee-c222198479fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 28 14:47:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   36C    P8    20W / 300W |  26439MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6819dc6-ff40-4f79-8685-02db3c6a8f77",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('pip install python-dotenv')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95534da-f206-4f29-a023-0b49a499bdf9",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.2.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.23.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install scikit-learn==1.2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af13c3b",
   "metadata": {
    "papermill": {
     "duration": 7.561173,
     "end_time": "2023-02-11T02:05:08.553027",
     "exception": false,
     "start_time": "2023-02-11T02:05:00.991854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# Libraries\n",
    "# =========================================================================================\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f108c3d",
   "metadata": {
    "papermill": {
     "duration": 0.01567,
     "end_time": "2023-02-11T02:05:08.574968",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.559298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Configurations\n",
    "# =========================================================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    upload_data = True\n",
    "    wandb = True\n",
    "    print_freq = 500\n",
    "    num_workers = 4\n",
    "    model = \"xlm-roberta-base\"\n",
    "    gradient_checkpointing = False\n",
    "    num_cycles = 0.5\n",
    "    warmup_ratio = 0.1\n",
    "    encoder_lr = 1e-5\n",
    "    decoder_lr = 1e-4\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    batch_size = 128#368# 32#128#64#32\n",
    "    weight_decay = 0.01\n",
    "    max_grad_norm = 0.012\n",
    "    max_len = 512\n",
    "    n_folds = 5\n",
    "    seed = 42\n",
    "    epochs = 5\n",
    "    data_url = \"/notebooks/kaggle_lecr/data/learning-equality-curriculum-recommendations\"\n",
    "    train_set_url = \"/notebooks/kaggle_lecr/output/ex12-uns-top50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf556033-94aa-4878-9379-1cd79a7bc14d",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb==0.13.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.13.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (6.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.3.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.16.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (2.28.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (60.10.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.0.11)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (3.1.31)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (5.9.3)\n",
      "Requirement already satisfied: pathtools in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (0.1.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (8.1.3)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (2.3)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (3.20.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb==0.13.3) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (1.26.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.13.3) (5.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinchir0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/kaggle_lecr/ipynb/wandb/run-20230228_144733-34hmlnnc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sinchir0/LECR/runs/34hmlnnc\" target=\"_blank\">ex12-trn-top50</a></strong> to <a href=\"https://wandb.ai/sinchir0/LECR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "if CFG.wandb:\n",
    "    os.system('pip install wandb==0.13.3')\n",
    "    import wandb\n",
    "\n",
    "    try:\n",
    "        # for kaggle\n",
    "        # from kaggle_secrets import UserSecretsClient\n",
    "        # user_secrets = UserSecretsClient()\n",
    "        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "        \n",
    "        # for paperspace\n",
    "        secret_value_0 = os.getenv('WANDB_API_KEY')\n",
    "        wandb.login(key=secret_value_0)\n",
    "        \n",
    "        anony = None\n",
    "    except:\n",
    "        anony = \"must\"\n",
    "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "\n",
    "    def class2dict(f):\n",
    "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "    run = wandb.init(project='LECR',\n",
    "                     entity=\"sinchir0\",\n",
    "                     name=NOTEBOOK_NAME,\n",
    "                     config=class2dict(CFG),\n",
    "                     group=\"trn\",\n",
    "                     job_type=\"train\",\n",
    "                     anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea8f99c",
   "metadata": {
    "papermill": {
     "duration": 0.014544,
     "end_time": "2023-02-11T02:05:08.595307",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.580763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Seed everything for deterministic results\n",
    "# =========================================================================================\n",
    "def seed_everything(cfg):\n",
    "    random.seed(cfg.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    torch.cuda.manual_seed(cfg.seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fd14795",
   "metadata": {
    "papermill": {
     "duration": 0.015773,
     "end_time": "2023-02-11T02:05:08.616987",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.601214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Data Loading\n",
    "# =========================================================================================\n",
    "def read_data(cfg):\n",
    "    # train = pd.read_csv(f\"{cfg.train_set_url}/train.csv\")\n",
    "    # train = pd.read_pickle(f\"{cfg.train_set_url}/train.pkl\")\n",
    "    train = pd.read_csv(f\"{cfg.train_set_url}/train_50.csv\")\n",
    "    train[\"content_titles\"] = train[\"content_titles\"].fillna(\"\")\n",
    "    \n",
    "    topics = pd.read_csv(cfg.data_url + \"/\" + \"topics.csv\")\n",
    "    content = pd.read_csv(cfg.data_url + \"/\" + \"content.csv\")\n",
    "    correlations = pd.read_csv(cfg.data_url + \"/\" + \"correlations.csv\")\n",
    "\n",
    "    topics[\"title\"] = topics[\"title\"].fillna(\"\")\n",
    "    content[\"title\"] = content[\"title\"].fillna(\"\")\n",
    "    \n",
    "    topics[\"description\"] = topics[\"description\"].fillna(\"\")\n",
    "    content[\"description\"] = content[\"description\"].fillna(\"\")\n",
    "    \n",
    "    content['text'] = content['text'].fillna(\"\")\n",
    "    \n",
    "    print(' ')\n",
    "    print('-' * 50)\n",
    "    print(f\"train.shape: {train.shape}\")\n",
    "    print(f\"correlations.shape: {correlations.shape}\")\n",
    "    return train, topics, content, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c94a6b",
   "metadata": {
    "papermill": {
     "duration": 0.013152,
     "end_time": "2023-02-11T02:05:08.635842",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.622690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(train: pd.DataFrame):\n",
    "    # Create feature column\n",
    "    # train['text'] = train['topics_titles'] + '[SEP]' + train['content_titles']\n",
    "    train['text'] = train['topics_texts'] + '[SEP]' + train['content_texts']\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d457e372",
   "metadata": {
    "papermill": {
     "duration": 0.017013,
     "end_time": "2023-02-11T02:05:08.658444",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.641431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_cat_info(train: pd.DataFrame, topics: pd.DataFrame, content:pd.DataFrame):\n",
    "    merge_train = pd.merge(train, topics[[\"id\", \"level\", \"category\"]], left_on=\"topics_ids\", right_on=\"id\", how=\"left\")\n",
    "    merge_train = merge_train.drop(\"id\", axis=1)\n",
    "    merge_train = pd.merge(merge_train, content[[\"id\", \"kind\"]], left_on=\"content_ids\", right_on=\"id\", how=\"left\")\n",
    "    merge_train = merge_train.drop(\"id\", axis=1)\n",
    "    \n",
    "    merge_train[\"level_tag\"] = merge_train[\"level\"].apply(lambda x: f\"[LEVEL{x}]\")\n",
    "    merge_train[\"category_tag\"] = merge_train[\"category\"].apply(lambda x: f\"[CATEGORY_{x.upper()}]\")\n",
    "    merge_train[\"kind_tag\"] = merge_train[\"kind\"].apply(lambda x: f\"[KIND_{x.upper()}]\")\n",
    "    \n",
    "    level_tag_list = sorted(merge_train[\"level_tag\"].unique()) \n",
    "    category_list = sorted(merge_train[\"category_tag\"].unique()) \n",
    "    kind_list = sorted(merge_train[\"kind_tag\"].unique()) \n",
    "    \n",
    "    # train['topics_titles'] = merge_train['level_tag'] + merge_train[\"category_tag\"] + merge_train['topics_titles'] \n",
    "    train['topics_texts'] = merge_train['level_tag'] + merge_train[\"category_tag\"] + merge_train['topics_texts'] \n",
    "    # train['content_titles'] = merge_train['kind_tag'] + merge_train['content_titles']\n",
    "    train['content_texts'] = merge_train['kind_tag'] + merge_train['content_texts']\n",
    "    \n",
    "    return train, level_tag_list, category_list, kind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a68033ec",
   "metadata": {
    "papermill": {
     "duration": 0.01453,
     "end_time": "2023-02-11T02:05:08.678562",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.664032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# CV split\n",
    "# =========================================================================================\n",
    "def cv_split(train, cfg):\n",
    "    kfold = StratifiedGroupKFold(n_splits = cfg.n_folds, shuffle = True, random_state = cfg.seed)\n",
    "    for num, (train_index, val_index) in enumerate(kfold.split(train, train['target'], train['topics_ids'])):\n",
    "        train.loc[val_index, 'fold'] = int(num)\n",
    "    train['fold'] = train['fold'].astype(int)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7007386",
   "metadata": {
    "papermill": {
     "duration": 0.016546,
     "end_time": "2023-02-11T02:05:08.702048",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.685502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# F2 score metric\n",
    "# =========================================================================================\n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f2 = tp / (tp + 0.2 * fp + 0.8 * fn)\n",
    "    return round(f2.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79f24de",
   "metadata": {
    "papermill": {
     "duration": 0.015781,
     "end_time": "2023-02-11T02:05:08.723530",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.707749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Get max length\n",
    "# =========================================================================================\n",
    "def get_max_length(train, cfg):\n",
    "    lengths = []\n",
    "    for text in tqdm(train['text'].fillna(\"\").values, total = len(train)):\n",
    "        length = len(cfg.tokenizer(text, add_special_tokens = False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "    cfg.max_len = min(max(lengths) + 5, cfg.max_len) # cls + sep + level + category + kind\n",
    "    print(f\"max_len: {cfg.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8d29cf",
   "metadata": {
    "papermill": {
     "duration": 0.058232,
     "end_time": "2023-02-11T02:05:08.787596",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.729364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Prepare input, tokenize\n",
    "# =========================================================================================\n",
    "def prepare_input(text, cfg):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "        max_length = cfg.max_len,\n",
    "        pad_to_max_length = True,\n",
    "        truncation = True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Custom dataset\n",
    "# =========================================================================================\n",
    "class custom_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "        self.labels = df['target'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item], self.cfg)\n",
    "        label = torch.tensor(self.labels[item], dtype = torch.float)\n",
    "        return inputs, label\n",
    "    \n",
    "# =========================================================================================\n",
    "# Collate function for training\n",
    "# =========================================================================================\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Mean pooling class\n",
    "# =========================================================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "# =========================================================================================\n",
    "# Model\n",
    "# =========================================================================================\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states = True)\n",
    "        self.config.hidden_dropout = 0.0\n",
    "        self.config.hidden_dropout_prob = 0.0\n",
    "        self.config.attention_dropout = 0.0\n",
    "        self.config.attention_probs_dropout_prob = 0.0\n",
    "        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n",
    "        # AutoTokenizer.from_pretrainedでadditional_special_tokensをした際は、増えたtoken分、新しい語彙として登録が必要らしい\n",
    "        # https://cocoinit23.com/pytorch-runtimeerror-cuda-error-device-side-assert-triggered/\n",
    "        self.model.resize_token_embeddings(len(cfg.tokenizer))\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "    \n",
    "# =========================================================================================\n",
    "# Helper functions\n",
    "# =========================================================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "# =========================================================================================\n",
    "# Train function loop\n",
    "# =========================================================================================\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled = True)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, target) in enumerate(train_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled = True):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch + 1, \n",
    "                          step, \n",
    "                          len(train_loader), \n",
    "                          remain = timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                          loss = losses,\n",
    "                          grad_norm = grad_norm,\n",
    "                          lr = scheduler.get_lr()[0]))\n",
    "    return losses.avg\n",
    "\n",
    "# =========================================================================================\n",
    "# Valid function loop\n",
    "# =========================================================================================\n",
    "def valid_fn(valid_loader, model, criterion, device, cfg):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, target) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().squeeze().to('cpu').numpy().reshape(-1))\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, \n",
    "                          len(valid_loader),\n",
    "                          loss = losses,\n",
    "                          remain = timeSince(start, float(step + 1) / len(valid_loader))))\n",
    "    predictions = np.concatenate(preds, axis = 0)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "# =========================================================================================\n",
    "# Get best threshold\n",
    "# =========================================================================================\n",
    "def get_best_threshold(x_val, val_predictions, correlations):\n",
    "    best_score = 0\n",
    "    best_threshold = None\n",
    "    for thres in np.arange(0.001, 0.1, 0.001):\n",
    "        x_val['predictions'] = np.where(val_predictions > thres, 1, 0)\n",
    "        x_val1 = x_val[x_val['predictions'] == 1]\n",
    "        x_val1 = x_val1.groupby(['topics_ids'])['content_ids'].unique().reset_index()\n",
    "        x_val1['content_ids'] = x_val1['content_ids'].apply(lambda x: ' '.join(x))\n",
    "        x_val1.columns = ['topic_id', 'predictions']\n",
    "        x_val0 = pd.Series(x_val['topics_ids'].unique())\n",
    "        x_val0 = x_val0[~x_val0.isin(x_val1['topic_id'])]\n",
    "        x_val0 = pd.DataFrame({'topic_id': x_val0.values, 'predictions': \"\"})\n",
    "        x_val_r = pd.concat([x_val1, x_val0], axis = 0, ignore_index = True)\n",
    "        x_val_r = x_val_r.merge(correlations, how = 'left', on = 'topic_id')\n",
    "        score = f2_score(x_val_r['content_ids'], x_val_r['predictions'])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = thres\n",
    "    return best_score, best_threshold\n",
    "    \n",
    "# =========================================================================================\n",
    "# Train & Evaluate\n",
    "# =========================================================================================\n",
    "def train_and_evaluate_one_fold(train, correlations, fold, cfg, add_topic_content: list):\n",
    "    # 高速化、計算の再現性は担保されない、https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    print(' ')\n",
    "    print(f\"========== fold: {fold} training ==========\")\n",
    "    # Split train & validation\n",
    "    x_train = train[train['fold'] != fold]\n",
    "    x_val = train[train['fold'] == fold]\n",
    "    \n",
    "    # categoryがsourceのtopicは評価に使わない\n",
    "    x_val = x_val[~x_val[\"topics_texts\"].str.contains(\"CATEGORY_SOURCE\")]\n",
    "    \n",
    "    # 追加したpositiveのtopic, contentは評価には使わない\n",
    "    x_val = x_val[~(x_val[\"topics_ids\"] + x_val[\"content_ids\"]).isin(add_topic_content)]\n",
    "    \n",
    "    valid_labels = x_val['target'].values\n",
    "    train_dataset = custom_dataset(x_train, cfg)\n",
    "    valid_dataset = custom_dataset(x_val, cfg)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = True, \n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "    # Get model\n",
    "    model = custom_model(cfg)\n",
    "    model.to(device)\n",
    "    # Optimizer\n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay = 0.0):\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "            'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "    optimizer_parameters = get_optimizer_params(\n",
    "        model, \n",
    "        encoder_lr = cfg.encoder_lr, \n",
    "        decoder_lr = cfg.decoder_lr,\n",
    "        weight_decay = cfg.weight_decay\n",
    "    )\n",
    "    optimizer = AdamW(\n",
    "        optimizer_parameters, \n",
    "        lr = cfg.encoder_lr, \n",
    "        eps = cfg.eps, \n",
    "        betas = cfg.betas\n",
    "    )\n",
    "    num_train_steps = int(len(x_train) / cfg.batch_size * cfg.epochs)\n",
    "    num_warmup_steps = num_train_steps * cfg.warmup_ratio\n",
    "    # Scheduler\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps = num_warmup_steps, \n",
    "        num_training_steps = num_train_steps, \n",
    "        num_cycles = cfg.num_cycles\n",
    "        )\n",
    "    # Training & Validation loop\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "    best_score = 0\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        start_time = time.time()\n",
    "        # Train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg)\n",
    "        # Validation\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device, cfg)\n",
    "        # Compute f2_score\n",
    "        score, threshold = get_best_threshold(x_val, predictions, correlations)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        print(f'Epoch {epoch+1} - Score: {score:.4f} - Threshold: {threshold:.5f}')\n",
    "        torch.save(\n",
    "            {'model': model.state_dict(), 'predictions': predictions}, \n",
    "            f\"{OUTPUT_DIR}/{cfg.model.replace('/', '-')}_fold{fold}_{cfg.seed}_epoch{epoch}.pth\"\n",
    "        )\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save(\n",
    "                {'model': model.state_dict(), 'predictions': predictions}, \n",
    "                f\"{OUTPUT_DIR}/{cfg.model.replace('/', '-')}_fold{fold}_{cfg.seed}_best_model.pth\"\n",
    "                )\n",
    "            val_predictions = predictions\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    # Get best threshold\n",
    "    best_score, best_threshold = get_best_threshold(x_val, val_predictions, correlations)\n",
    "    # Save Score, Threshold\n",
    "    score = {\"best_score\": best_score, \"best_threshold\": best_threshold}\n",
    "    with open(f\"{OUTPUT_DIR}/score.pkl\", \"wb\") as f:\n",
    "        pickle.dump(score, f)\n",
    "    print(f'Our CV score is {best_score} using a threshold of {best_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3f57c04",
   "metadata": {
    "papermill": {
     "duration": 0.019865,
     "end_time": "2023-02-11T02:05:08.813594",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.793729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed everything\n",
    "seed_everything(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75b78f49",
   "metadata": {
    "papermill": {
     "duration": 22.091749,
     "end_time": "2023-02-11T02:05:30.911554",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.819805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "train.shape: (3075850, 5)\n",
      "correlations.shape: (61517, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train, topics, content, correlations = read_data(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07e4ae1f-e06f-4ed3-b3a9-3bebe8d28eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={\"topics_titles\":\"topics_texts\",\"content_titles\":\"content_texts\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a72c73ae-6a03-4db9-8f7f-eba633295b17",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics_ids       0\n",
       "content_ids      0\n",
       "topics_texts     0\n",
       "content_texts    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0e6c17a-1e04-43e3-8522-645a7e50d555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# positive sampleを足す\n",
    "def add_positive_sample(train: pd.DataFrame, correlations: pd.DataFrame, topics: pd.DataFrame, content: pd.DataFrame):\n",
    "    \n",
    "    # topic_text_dict = dict(zip(topics[\"id\"], topics['title'] + \" \" + topics['description']))\n",
    "    # content_text_dict = dict(zip(content[\"id\"], content['title'] + \" \" + content['description']))\n",
    "    topic_text_dict = dict(zip(topics[\"id\"], topics['title']))\n",
    "    content_text_dict = dict(zip(content[\"id\"], content['title']))\n",
    "    \n",
    "    correlations[\"content_ids_list\"] = correlations[\"content_ids\"].apply(lambda x : x.split())\n",
    "    \n",
    "    all_positive_sample = correlations.explode(\"content_ids_list\")[[\"topic_id\",\"content_ids_list\"]]\n",
    "    all_positive_sample = all_positive_sample.rename(columns={\"topic_id\":\"topics_ids\",\"content_ids_list\":\"content_ids\"})\n",
    "    \n",
    "    all_positive_sample[\"topics_texts\"] = all_positive_sample[\"topics_ids\"].map(topic_text_dict)\n",
    "    all_positive_sample[\"content_texts\"] = all_positive_sample[\"content_ids\"].map(content_text_dict)\n",
    "    all_positive_sample[\"target\"] = 1\n",
    "    \n",
    "    all_positive_sample = all_positive_sample.reset_index(drop=True)\n",
    "    \n",
    "    # 追加するtopic, contentのみを持つlistを生成\n",
    "    all_positive_topic_content = (all_positive_sample[\"topics_ids\"] + all_positive_sample[\"content_ids\"]).tolist()\n",
    "    train_positive = train[train[\"target\"] == 1]\n",
    "    train_positive_topic_content = (train_positive[\"topics_ids\"] + train_positive[\"content_ids\"]).tolist()\n",
    "    add_topic_content = list(set(all_positive_topic_content) - set(train_positive_topic_content))\n",
    "    \n",
    "    # trainにpositive sampleを追加\n",
    "    train = pd.concat([train, all_positive_sample]).drop_duplicates(subset=[\"topics_ids\",\"content_ids\"], keep='first')\n",
    "    train = train.sort_values(\"topics_ids\")\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    return train, add_topic_content\n",
    "\n",
    "train, add_topic_content = add_positive_sample(train, correlations, topics, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa349b-7b57-43d6-844e-533dbbeced8a",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train[\"topics_texts\"] = train[\"topics_texts\"].apply(lambda x: x[:300])\n",
    "# train[\"content_texts\"] = train[\"content_texts\"].apply(lambda x: x[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53157afd-2fbf-4421-adf2-b6cd94da55fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics_ids</th>\n",
       "      <th>content_ids</th>\n",
       "      <th>topics_texts</th>\n",
       "      <th>content_texts</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_6cd1bd6f1e49</td>\n",
       "      <td>Откриването на резисторите &gt; Открития и проект...</td>\n",
       "      <td>Диелектрици в кондензатори</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_c8184b4bba5d</td>\n",
       "      <td>Откриването на резисторите &gt; Открития и проект...</td>\n",
       "      <td>Електричен ток</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_678145c4cfe4</td>\n",
       "      <td>Откриването на резисторите &gt; Открития и проект...</td>\n",
       "      <td>Кондензатори и капацитет</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_ded49059e260</td>\n",
       "      <td>Откриването на резисторите &gt; Открития и проект...</td>\n",
       "      <td>Задача за събиране на съпротивления</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_0c885859d4fa</td>\n",
       "      <td>Откриването на резисторите &gt; Открития и проект...</td>\n",
       "      <td>Последователно свързани кондензатори</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topics_ids     content_ids  \\\n",
       "0  t_00004da3a1b2  c_6cd1bd6f1e49   \n",
       "1  t_00004da3a1b2  c_c8184b4bba5d   \n",
       "2  t_00004da3a1b2  c_678145c4cfe4   \n",
       "3  t_00004da3a1b2  c_ded49059e260   \n",
       "4  t_00004da3a1b2  c_0c885859d4fa   \n",
       "\n",
       "                                        topics_texts  \\\n",
       "0  Откриването на резисторите > Открития и проект...   \n",
       "1  Откриването на резисторите > Открития и проект...   \n",
       "2  Откриването на резисторите > Открития и проект...   \n",
       "3  Откриването на резисторите > Открития и проект...   \n",
       "4  Откриването на резисторите > Открития и проект...   \n",
       "\n",
       "                          content_texts  target  \n",
       "0            Диелектрици в кондензатори       0  \n",
       "1                        Електричен ток       0  \n",
       "2              Кондензатори и капацитет       0  \n",
       "3   Задача за събиране на съпротивления       0  \n",
       "4  Последователно свързани кондензатори       0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cacb8ef-7b40-44a8-9923-e811d089ff1c",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51859"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(add_topic_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27837264",
   "metadata": {
    "papermill": {
     "duration": 0.02252,
     "end_time": "2023-02-11T02:05:30.947474",
     "exception": false,
     "start_time": "2023-02-11T02:05:30.924954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train[:1000]\n",
    "    CFG.epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4205a7c0",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.095627,
     "end_time": "2023-02-11T02:05:33.051735",
     "exception": false,
     "start_time": "2023-02-11T02:05:30.956108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, level_tag_list, category_list, kind_list = merge_cat_info(train, topics, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb705e19",
   "metadata": {
    "papermill": {
     "duration": 0.227458,
     "end_time": "2023-02-11T02:05:33.352932",
     "exception": false,
     "start_time": "2023-02-11T02:05:33.125474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a752ad2-daa2-4ef1-9af2-854e69edc6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics_ids</th>\n",
       "      <th>content_ids</th>\n",
       "      <th>topics_texts</th>\n",
       "      <th>content_texts</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_6cd1bd6f1e49</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "      <td>[KIND_VIDEO]Диелектрици в кондензатори</td>\n",
       "      <td>0</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_c8184b4bba5d</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "      <td>[KIND_VIDEO]Електричен ток</td>\n",
       "      <td>0</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_678145c4cfe4</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "      <td>[KIND_VIDEO]Кондензатори и капацитет</td>\n",
       "      <td>0</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_ded49059e260</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "      <td>[KIND_VIDEO]Задача за събиране на съпротивления</td>\n",
       "      <td>0</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_0c885859d4fa</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "      <td>[KIND_VIDEO]Последователно свързани кондензатори</td>\n",
       "      <td>0</td>\n",
       "      <td>[LEVEL4][CATEGORY_SOURCE]Откриването на резист...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topics_ids     content_ids  \\\n",
       "0  t_00004da3a1b2  c_6cd1bd6f1e49   \n",
       "1  t_00004da3a1b2  c_c8184b4bba5d   \n",
       "2  t_00004da3a1b2  c_678145c4cfe4   \n",
       "3  t_00004da3a1b2  c_ded49059e260   \n",
       "4  t_00004da3a1b2  c_0c885859d4fa   \n",
       "\n",
       "                                        topics_texts  \\\n",
       "0  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...   \n",
       "1  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...   \n",
       "2  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...   \n",
       "3  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...   \n",
       "4  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...   \n",
       "\n",
       "                                      content_texts  target  \\\n",
       "0            [KIND_VIDEO]Диелектрици в кондензатори       0   \n",
       "1                        [KIND_VIDEO]Електричен ток       0   \n",
       "2              [KIND_VIDEO]Кондензатори и капацитет       0   \n",
       "3   [KIND_VIDEO]Задача за събиране на съпротивления       0   \n",
       "4  [KIND_VIDEO]Последователно свързани кондензатори       0   \n",
       "\n",
       "                                                text  \n",
       "0  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...  \n",
       "1  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...  \n",
       "2  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...  \n",
       "3  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...  \n",
       "4  [LEVEL4][CATEGORY_SOURCE]Откриването на резист...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69ad3a19-92b1-4794-9bd7-6daee885cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xlm-roberta-base'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09133fac",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.251238,
     "end_time": "2023-02-11T02:05:41.664455",
     "exception": false,
     "start_time": "2023-02-11T02:05:33.413217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "CFG.tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model,\n",
    "    additional_special_tokens = level_tag_list + category_list + kind_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc3017c7",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018461,
     "end_time": "2023-02-11T02:05:41.691787",
     "exception": false,
     "start_time": "2023-02-11T02:05:41.673326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[LEVEL0]',\n",
       " '[LEVEL10]',\n",
       " '[LEVEL1]',\n",
       " '[LEVEL2]',\n",
       " '[LEVEL3]',\n",
       " '[LEVEL4]',\n",
       " '[LEVEL5]',\n",
       " '[LEVEL6]',\n",
       " '[LEVEL7]',\n",
       " '[LEVEL8]',\n",
       " '[LEVEL9]',\n",
       " '[CATEGORY_ALIGNED]',\n",
       " '[CATEGORY_SOURCE]',\n",
       " '[CATEGORY_SUPPLEMENTAL]',\n",
       " '[KIND_AUDIO]',\n",
       " '[KIND_DOCUMENT]',\n",
       " '[KIND_EXERCISE]',\n",
       " '[KIND_HTML5]',\n",
       " '[KIND_VIDEO]']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.tokenizer.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b490a510-9e68-4203-b3a1-9bd5ce3c787a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# categoryがsourceのnegativeデータを減らし、計算時間を短くする\n",
    "# train[\"is_category_source\"] = train[\"topics_texts\"].str.contains(\"CATEGORY_SOURCE\")\n",
    "# train = train[~(train[\"is_category_source\"] & (train[\"target\"] == 0))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871bf1d-8673-4cec-8472-7daa58e3e865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 計算を終わらせるため、行を減らす\n",
    "# if not CFG.debug:\n",
    "#     train = train.sample(200000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e5a3ce5",
   "metadata": {
    "papermill": {
     "duration": 24.616901,
     "end_time": "2023-02-11T02:06:06.316153",
     "exception": false,
     "start_time": "2023-02-11T02:05:41.699252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CV split\n",
    "train = cv_split(train, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "234ea5e9-9f5c-4e84-a884-de3ab5d0cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = train[[\"topics_ids\",\"fold\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be63cf4e-0915-42ed-b32b-9adf32adb3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.drop_duplicates().to_csv(\"topics_ids_fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb66dca3-cbb8-4d3e-a012-eb589fc18c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_list = train[train[\"fold\"] == 0][\"topics_ids\"].unique().tolist()\n",
    "with open(f\"{OUTPUT_DIR}/fold_0_topics_ids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fold0_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "287e8991-6d5a-470d-9459-2cc95718db13",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    625884\n",
      "0    625596\n",
      "1    625534\n",
      "3    625402\n",
      "2    625293\n",
      "Name: fold, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"fold\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "494577d4-2513-465c-938c-c4d635829e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84d901da-9881-4008-8a1d-53655a9722ec",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2847790\n",
       "1     279919\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07e9b843",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 81.097871,
     "end_time": "2023-02-11T02:07:27.589260",
     "exception": false,
     "start_time": "2023-02-11T02:06:06.491389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62368c09d38e4ff48ce985f4d052a7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3127709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len: 233\n"
     ]
    }
   ],
   "source": [
    "# Get max length\n",
    "get_max_length(train, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "896807cf-cf68-42f9-aca1-118b255065e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5253160",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 17391.060041,
     "end_time": "2023-02-11T06:57:18.656824",
     "exception": false,
     "start_time": "2023-02-11T02:07:27.596783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f1061353524817bbb5ee6c1bbe54d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/19547] Elapsed 0m 1s (remain 632m 22s) Loss: 0.8759(0.8759) Grad: inf  LR: 0.00000000  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_510/3815796829.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train and evaluate one fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_and_evaluate_one_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_topic_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_510/1904467998.py\u001b[0m in \u001b[0;36mtrain_and_evaluate_one_fold\u001b[0;34m(train, correlations, fold, cfg, add_topic_content)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mavg_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_510/1904467998.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train and evaluate one fold\n",
    "train_and_evaluate_one_fold(train, correlations, 0, CFG, add_topic_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f858de-30f7-455a-856f-d9b1631f087f",
   "metadata": {},
   "source": [
    "# Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a8cd3-0dc7-453c-b37e-e94d125fc681",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"pip install kaggle\")\n",
    "os.system(\"mkdir -p ~/.kaggle/\")\n",
    "os.system(\"cp /notebooks/kaggle_lecr/kaggle.json ~/.kaggle/\")\n",
    "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a516b-6edc-4aac-88c5-93f58b6ece6c",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import json\n",
    "\n",
    "def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "    if \"_\" in dataset_name:\n",
    "        raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'sinchir0/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n",
    "\n",
    "if CFG.upload_data:\n",
    "    print(f\"Create Dataset name:{NOTEBOOK_NAME}, output_dir:{OUTPUT_DIR}\")\n",
    "    dataset_create_new(dataset_name=NOTEBOOK_NAME, upload_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fda75-46ff-44dd-9bac-ec7fb5dc0e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879017b-061f-4d99-9f49-e59ab8b2884c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17548.763501,
   "end_time": "2023-02-11T06:57:21.580304",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-11T02:04:52.816803",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "218592928185498e9d59df2150307773": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a52632c7335f4547b3ac2e5873e80780",
        "IPY_MODEL_2ddfc44c7cdf4e50b90af044edb241e7",
        "IPY_MODEL_52fc9a4bd70c4d5d83cfda3bf9c96398"
       ],
       "layout": "IPY_MODEL_a83b337e4b59457a8ac5de9174f9cf9d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2ddfc44c7cdf4e50b90af044edb241e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c155ce2411e4d16b964ab60e162b45c",
       "max": 615170,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9cc63961d65a4e05bc533f5a7c6301e6",
       "tabbable": null,
       "tooltip": null,
       "value": 615170
      }
     },
     "52fc9a4bd70c4d5d83cfda3bf9c96398": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81d6d3f955d94a10a8a9563343a028a4",
       "placeholder": "​",
       "style": "IPY_MODEL_71acb0f9429c474a93233c1f859e53e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 615170/615170 [01:21&lt;00:00, 3806.35it/s]"
      }
     },
     "71acb0f9429c474a93233c1f859e53e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "81d6d3f955d94a10a8a9563343a028a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c155ce2411e4d16b964ab60e162b45c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cc63961d65a4e05bc533f5a7c6301e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a52632c7335f4547b3ac2e5873e80780": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f62b4326bfaf4b439f5b53f0eef9e80d",
       "placeholder": "​",
       "style": "IPY_MODEL_e26c5dc8f53343b399e78f5d540eaf0d",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "a83b337e4b59457a8ac5de9174f9cf9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e26c5dc8f53343b399e78f5d540eaf0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f62b4326bfaf4b439f5b53f0eef9e80d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
