{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2b29e0-150c-47b3-9f56-e0241255ca87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"ex11-trn-all-MiniLM-L12-v2-mnrloss-ep5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd0b75a-2889-48af-b1df-a47cb38584bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OUTPUT_DIR = f\"/notebooks/kaggle_lecr/output/{NOTEBOOK_NAME}\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea3d0df-f4e8-4202-a89b-f5926005aa42",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch==1.12.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.12.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.9/site-packages (from torch==1.12.0) (4.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers==0.12.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.12.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.20.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (4.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (1.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (4.64.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (3.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (0.13.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.20.1) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip3 install torch==1.12.0 --extra-index-url https://download.pytorch.org/whl/cu116\")\n",
    "os.system(\"pip install tokenizers==0.12.1\")\n",
    "os.system(\"pip install transformers==4.20.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09c789d-506f-4886-b7ee-c222198479fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 11 14:46:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   50C    P8    24W / 230W |   2511MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6819dc6-ff40-4f79-8685-02db3c6a8f77",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('pip install python-dotenv')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95534da-f206-4f29-a023-0b49a499bdf9",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.2.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.23.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install scikit-learn==1.2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af13c3b",
   "metadata": {
    "papermill": {
     "duration": 7.561173,
     "end_time": "2023-02-11T02:05:08.553027",
     "exception": false,
     "start_time": "2023-02-11T02:05:00.991854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# Libraries\n",
    "# =========================================================================================\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f108c3d",
   "metadata": {
    "papermill": {
     "duration": 0.01567,
     "end_time": "2023-02-11T02:05:08.574968",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.559298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Configurations\n",
    "# =========================================================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    upload_data = True\n",
    "    wandb = True\n",
    "    print_freq = 500\n",
    "    num_workers = 4\n",
    "    # model = \"xlm-roberta-base\"\n",
    "    model = \"/notebooks/kaggle_lecr/output/ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10\"\n",
    "    gradient_checkpointing = False\n",
    "    num_cycles = 0.5\n",
    "    warmup_ratio = 0.1\n",
    "    encoder_lr = 1e-5\n",
    "    decoder_lr = 1e-4\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    batch_size = 32#128#368# 32#128#64#32\n",
    "    weight_decay = 0.01\n",
    "    max_grad_norm = 0.012\n",
    "    max_len = 512\n",
    "    n_folds = 5\n",
    "    seed = 42\n",
    "    epochs = 5\n",
    "    data_url = \"/notebooks/kaggle_lecr/data/learning-equality-curriculum-recommendations\"\n",
    "    train_set_url = \"/notebooks/kaggle_lecr/output/ex11-uns-all-MiniLM-L12-v2-mnrloss-ep10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf556033-94aa-4878-9379-1cd79a7bc14d",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb==0.13.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.13.3)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.3.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.0.11)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (8.1.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (6.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (2.28.1)\n",
      "Requirement already satisfied: pathtools in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (0.1.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (5.9.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (60.10.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (3.1.31)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.16.0)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (3.20.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb==0.13.3) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (2022.9.24)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.13.3) (5.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinchir0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/kaggle_lecr/ipynb/wandb/run-20230311_144653-16ib5p8s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sinchir0/LECR/runs/16ib5p8s\" target=\"_blank\">ex11-trn-all-MiniLM-L12-v2-mnrloss-ep5</a></strong> to <a href=\"https://wandb.ai/sinchir0/LECR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "if CFG.wandb:\n",
    "    os.system('pip install wandb==0.13.3')\n",
    "    import wandb\n",
    "\n",
    "    try:\n",
    "        # for kaggle\n",
    "        # from kaggle_secrets import UserSecretsClient\n",
    "        # user_secrets = UserSecretsClient()\n",
    "        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "        \n",
    "        # for paperspace\n",
    "        secret_value_0 = os.getenv('WANDB_API_KEY')\n",
    "        wandb.login(key=secret_value_0)\n",
    "        \n",
    "        anony = None\n",
    "    except:\n",
    "        anony = \"must\"\n",
    "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "\n",
    "    def class2dict(f):\n",
    "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "    run = wandb.init(project='LECR',\n",
    "                     entity=\"sinchir0\",\n",
    "                     name=NOTEBOOK_NAME,\n",
    "                     config=class2dict(CFG),\n",
    "                     group=\"trn\",\n",
    "                     job_type=\"train\",\n",
    "                     anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea8f99c",
   "metadata": {
    "papermill": {
     "duration": 0.014544,
     "end_time": "2023-02-11T02:05:08.595307",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.580763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Seed everything for deterministic results\n",
    "# =========================================================================================\n",
    "def seed_everything(cfg):\n",
    "    random.seed(cfg.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    torch.cuda.manual_seed(cfg.seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd14795",
   "metadata": {
    "papermill": {
     "duration": 0.015773,
     "end_time": "2023-02-11T02:05:08.616987",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.601214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Data Loading\n",
    "# =========================================================================================\n",
    "def read_data(cfg):\n",
    "    # train = pd.read_csv(f\"{cfg.train_set_url}/train.csv\")\n",
    "    train = pd.read_pickle(f\"{cfg.train_set_url}/train.pkl\")\n",
    "    \n",
    "    topics = pd.read_csv(cfg.data_url + \"/\" + \"topics.csv\")\n",
    "    content = pd.read_csv(cfg.data_url + \"/\" + \"content.csv\")\n",
    "    correlations = pd.read_csv(cfg.data_url + \"/\" + \"correlations.csv\")\n",
    "\n",
    "    topics[\"title\"] = topics[\"title\"].fillna(\"\")\n",
    "    content[\"title\"] = content[\"title\"].fillna(\"\")\n",
    "    \n",
    "    topics[\"description\"] = topics[\"description\"].fillna(\"\")\n",
    "    content[\"description\"] = content[\"description\"].fillna(\"\")\n",
    "    \n",
    "    content['text'] = content['text'].fillna(\"\")\n",
    "    \n",
    "    print(' ')\n",
    "    print('-' * 50)\n",
    "    print(f\"train.shape: {train.shape}\")\n",
    "    print(f\"correlations.shape: {correlations.shape}\")\n",
    "    return train, topics, content, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c94a6b",
   "metadata": {
    "papermill": {
     "duration": 0.013152,
     "end_time": "2023-02-11T02:05:08.635842",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.622690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(train: pd.DataFrame):\n",
    "    # Create feature column\n",
    "    # train['text'] = train['topics_titles'] + '[SEP]' + train['content_titles']\n",
    "    train['text'] = train['topics_texts'] + '[SEP]' + train['content_texts']\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d457e372",
   "metadata": {
    "papermill": {
     "duration": 0.017013,
     "end_time": "2023-02-11T02:05:08.658444",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.641431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_cat_info(train: pd.DataFrame, topics: pd.DataFrame, content:pd.DataFrame):\n",
    "    merge_train = pd.merge(train, topics[[\"id\", \"level\", \"category\"]], left_on=\"topics_ids\", right_on=\"id\", how=\"left\")\n",
    "    merge_train = merge_train.drop(\"id\", axis=1)\n",
    "    merge_train = pd.merge(merge_train, content[[\"id\", \"kind\"]], left_on=\"content_ids\", right_on=\"id\", how=\"left\")\n",
    "    merge_train = merge_train.drop(\"id\", axis=1)\n",
    "    \n",
    "    merge_train[\"level_tag\"] = merge_train[\"level\"].apply(lambda x: f\"[LEVEL{x}]\")\n",
    "    merge_train[\"category_tag\"] = merge_train[\"category\"].apply(lambda x: f\"[CATEGORY_{x.upper()}]\")\n",
    "    merge_train[\"kind_tag\"] = merge_train[\"kind\"].apply(lambda x: f\"[KIND_{x.upper()}]\")\n",
    "    \n",
    "    level_tag_list = sorted(merge_train[\"level_tag\"].unique()) \n",
    "    category_list = sorted(merge_train[\"category_tag\"].unique()) \n",
    "    kind_list = sorted(merge_train[\"kind_tag\"].unique()) \n",
    "    \n",
    "    # train['topics_titles'] = merge_train['level_tag'] + merge_train[\"category_tag\"] + merge_train['topics_titles'] \n",
    "    train['topics_texts'] = merge_train['level_tag'] + merge_train[\"category_tag\"] + merge_train['topics_texts'] \n",
    "    # train['content_titles'] = merge_train['kind_tag'] + merge_train['content_titles']\n",
    "    train['content_texts'] = merge_train['kind_tag'] + merge_train['content_texts']\n",
    "    \n",
    "    return train, level_tag_list, category_list, kind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a68033ec",
   "metadata": {
    "papermill": {
     "duration": 0.01453,
     "end_time": "2023-02-11T02:05:08.678562",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.664032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# CV split\n",
    "# =========================================================================================\n",
    "def cv_split(train, cfg):\n",
    "    kfold = StratifiedGroupKFold(n_splits = cfg.n_folds, shuffle = True, random_state = cfg.seed)\n",
    "    for num, (train_index, val_index) in enumerate(kfold.split(train, train['target'], train['topics_ids'])):\n",
    "        train.loc[val_index, 'fold'] = int(num)\n",
    "    train['fold'] = train['fold'].astype(int)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7007386",
   "metadata": {
    "papermill": {
     "duration": 0.016546,
     "end_time": "2023-02-11T02:05:08.702048",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.685502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# F2 score metric\n",
    "# =========================================================================================\n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f2 = tp / (tp + 0.2 * fp + 0.8 * fn)\n",
    "    return round(f2.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79f24de",
   "metadata": {
    "papermill": {
     "duration": 0.015781,
     "end_time": "2023-02-11T02:05:08.723530",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.707749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Get max length\n",
    "# =========================================================================================\n",
    "def get_max_length(train, cfg):\n",
    "    lengths = []\n",
    "    for text in tqdm(train['text'].fillna(\"\").values, total = len(train)):\n",
    "        length = len(cfg.tokenizer(text, add_special_tokens = False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "    cfg.max_len = min(max(lengths) + 5, cfg.max_len) # cls + sep + level + category + kind\n",
    "    print(f\"max_len: {cfg.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8d29cf",
   "metadata": {
    "papermill": {
     "duration": 0.058232,
     "end_time": "2023-02-11T02:05:08.787596",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.729364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Prepare input, tokenize\n",
    "# =========================================================================================\n",
    "def prepare_input(text, cfg):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "        max_length = cfg.max_len,\n",
    "        pad_to_max_length = True,\n",
    "        truncation = True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Custom dataset\n",
    "# =========================================================================================\n",
    "class custom_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "        self.labels = df['target'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item], self.cfg)\n",
    "        label = torch.tensor(self.labels[item], dtype = torch.float)\n",
    "        return inputs, label\n",
    "    \n",
    "# =========================================================================================\n",
    "# Collate function for training\n",
    "# =========================================================================================\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Mean pooling class\n",
    "# =========================================================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "# =========================================================================================\n",
    "# Model\n",
    "# =========================================================================================\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states = True)\n",
    "        self.config.hidden_dropout = 0.0\n",
    "        self.config.hidden_dropout_prob = 0.0\n",
    "        self.config.attention_dropout = 0.0\n",
    "        self.config.attention_probs_dropout_prob = 0.0\n",
    "        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n",
    "        # AutoTokenizer.from_pretrainedでadditional_special_tokensをした際は、増えたtoken分、新しい語彙として登録が必要らしい\n",
    "        # https://cocoinit23.com/pytorch-runtimeerror-cuda-error-device-side-assert-triggered/\n",
    "        self.model.resize_token_embeddings(len(cfg.tokenizer))\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "    \n",
    "# =========================================================================================\n",
    "# Helper functions\n",
    "# =========================================================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "# =========================================================================================\n",
    "# Train function loop\n",
    "# =========================================================================================\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled = True)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, target) in enumerate(train_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled = True):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch + 1, \n",
    "                          step, \n",
    "                          len(train_loader), \n",
    "                          remain = timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                          loss = losses,\n",
    "                          grad_norm = grad_norm,\n",
    "                          lr = scheduler.get_lr()[0]))\n",
    "    return losses.avg\n",
    "\n",
    "# =========================================================================================\n",
    "# Valid function loop\n",
    "# =========================================================================================\n",
    "def valid_fn(valid_loader, model, criterion, device, cfg):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, target) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().squeeze().to('cpu').numpy().reshape(-1))\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, \n",
    "                          len(valid_loader),\n",
    "                          loss = losses,\n",
    "                          remain = timeSince(start, float(step + 1) / len(valid_loader))))\n",
    "    predictions = np.concatenate(preds, axis = 0)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "# =========================================================================================\n",
    "# Get best threshold\n",
    "# =========================================================================================\n",
    "def get_best_threshold(x_val, val_predictions, correlations):\n",
    "    best_score = 0\n",
    "    best_threshold = None\n",
    "    for thres in np.arange(0.001, 0.1, 0.001):\n",
    "        x_val['predictions'] = np.where(val_predictions > thres, 1, 0)\n",
    "        x_val1 = x_val[x_val['predictions'] == 1]\n",
    "        x_val1 = x_val1.groupby(['topics_ids'])['content_ids'].unique().reset_index()\n",
    "        x_val1['content_ids'] = x_val1['content_ids'].apply(lambda x: ' '.join(x))\n",
    "        x_val1.columns = ['topic_id', 'predictions']\n",
    "        x_val0 = pd.Series(x_val['topics_ids'].unique())\n",
    "        x_val0 = x_val0[~x_val0.isin(x_val1['topic_id'])]\n",
    "        x_val0 = pd.DataFrame({'topic_id': x_val0.values, 'predictions': \"\"})\n",
    "        x_val_r = pd.concat([x_val1, x_val0], axis = 0, ignore_index = True)\n",
    "        x_val_r = x_val_r.merge(correlations, how = 'left', on = 'topic_id')\n",
    "        score = f2_score(x_val_r['content_ids'], x_val_r['predictions'])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = thres\n",
    "    return best_score, best_threshold\n",
    "    \n",
    "# =========================================================================================\n",
    "# Train & Evaluate\n",
    "# =========================================================================================\n",
    "def train_and_evaluate_one_fold(train, correlations, fold, cfg, add_topic_content: list):\n",
    "    # 高速化、計算の再現性は担保されない、https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    print(' ')\n",
    "    print(f\"========== fold: {fold} training ==========\")\n",
    "    # Split train & validation\n",
    "    x_train = train[train['fold'] != fold]\n",
    "    x_val = train[train['fold'] == fold]\n",
    "    \n",
    "    # categoryがsourceのtopicは評価に使わない\n",
    "    x_val = x_val[~x_val[\"topics_texts\"].str.contains(\"CATEGORY_SOURCE\")]\n",
    "    \n",
    "    # 追加したpositiveのtopic, contentは評価には使わない\n",
    "    x_val = x_val[~(x_val[\"topics_ids\"] + x_val[\"content_ids\"]).isin(add_topic_content)]\n",
    "    \n",
    "    valid_labels = x_val['target'].values\n",
    "    train_dataset = custom_dataset(x_train, cfg)\n",
    "    valid_dataset = custom_dataset(x_val, cfg)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = True, \n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "    # Get model\n",
    "    model = custom_model(cfg)\n",
    "    model.to(device)\n",
    "    # Optimizer\n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay = 0.0):\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "            'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "    optimizer_parameters = get_optimizer_params(\n",
    "        model, \n",
    "        encoder_lr = cfg.encoder_lr, \n",
    "        decoder_lr = cfg.decoder_lr,\n",
    "        weight_decay = cfg.weight_decay\n",
    "    )\n",
    "    optimizer = AdamW(\n",
    "        optimizer_parameters, \n",
    "        lr = cfg.encoder_lr, \n",
    "        eps = cfg.eps, \n",
    "        betas = cfg.betas\n",
    "    )\n",
    "    num_train_steps = int(len(x_train) / cfg.batch_size * cfg.epochs)\n",
    "    num_warmup_steps = num_train_steps * cfg.warmup_ratio\n",
    "    # Scheduler\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps = num_warmup_steps, \n",
    "        num_training_steps = num_train_steps, \n",
    "        num_cycles = cfg.num_cycles\n",
    "        )\n",
    "    # Training & Validation loop\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "    best_score = 0\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        start_time = time.time()\n",
    "        # Train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg)\n",
    "        # Validation\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device, cfg)\n",
    "        # Compute f2_score\n",
    "        score, threshold = get_best_threshold(x_val, predictions, correlations)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        print(f'Epoch {epoch+1} - Score: {score:.4f} - Threshold: {threshold:.5f}')\n",
    "        torch.save(\n",
    "            {'model': model.state_dict(), 'predictions': predictions}, \n",
    "            f\"{OUTPUT_DIR}/{cfg.model.replace('/', '-')}_fold{fold}_{cfg.seed}_epoch{epoch}.pth\"\n",
    "        )\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save(\n",
    "                {'model': model.state_dict(), 'predictions': predictions}, \n",
    "                f\"{OUTPUT_DIR}/{cfg.model.replace('/', '-')}_fold{fold}_{cfg.seed}_best_model.pth\"\n",
    "                )\n",
    "            val_predictions = predictions\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    # Get best threshold\n",
    "    best_score, best_threshold = get_best_threshold(x_val, val_predictions, correlations)\n",
    "    # Save Score, Threshold\n",
    "    score = {\"best_score\": best_score, \"best_threshold\": best_threshold}\n",
    "    with open(f\"{OUTPUT_DIR}/score.pkl\", \"wb\") as f:\n",
    "        pickle.dump(score, f)\n",
    "    print(f'Our CV score is {best_score} using a threshold of {best_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3f57c04",
   "metadata": {
    "papermill": {
     "duration": 0.019865,
     "end_time": "2023-02-11T02:05:08.813594",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.793729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed everything\n",
    "seed_everything(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75b78f49",
   "metadata": {
    "papermill": {
     "duration": 22.091749,
     "end_time": "2023-02-11T02:05:30.911554",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.819805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "train.shape: (615170, 5)\n",
      "correlations.shape: (61517, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train, topics, content, correlations = read_data(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a72c73ae-6a03-4db9-8f7f-eba633295b17",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics_ids       0\n",
       "content_ids      0\n",
       "topics_texts     0\n",
       "content_texts    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afe8cc7d-d578-413c-bb19-861b71ab457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9037b72af3f449819ed32a95d8a58dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_parent_text(topics: pd.DataFrame):\n",
    "    topics = topics.fillna('')\n",
    "    id_full_text = {}\n",
    "    id_to_text = {}\n",
    "    for i, row in topics.iterrows():\n",
    "        id_to_text[row.id] = [row.title, row.parent]\n",
    "    print('done')\n",
    "    def get_full_text(id):\n",
    "        if id in id_full_text:\n",
    "            return id_full_text[id]\n",
    "        data = id_to_text[id]\n",
    "        # full_text = f'{data[0]} < {get_full_text(data[1])}' if data[1] != '' else data[0]\n",
    "        full_text = f'{data[0]} > {get_full_text(data[1])}' if data[1] != '' else data[0]\n",
    "        id_full_text[id] = full_text\n",
    "        return full_text\n",
    "    tqdm.pandas()\n",
    "    topics['title'] = topics.id.progress_apply(get_full_text)\n",
    "    # Sort by title length to make inference faster\n",
    "    topics['length'] = topics['title'].apply(lambda x: len(x))\n",
    "    topics.sort_values('length', inplace = True)\n",
    "    del id_full_text\n",
    "    del id_to_text\n",
    "    return topics\n",
    "\n",
    "# add parent text\n",
    "topics = add_parent_text(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0e6c17a-1e04-43e3-8522-645a7e50d555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# positive sampleを足す\n",
    "def add_positive_sample(train: pd.DataFrame, correlations: pd.DataFrame, topics: pd.DataFrame, content: pd.DataFrame):\n",
    "    \n",
    "    topic_text_dict = dict(zip(topics[\"id\"], topics['title'] + \" \" + topics['description']))\n",
    "    content_text_dict = dict(zip(content[\"id\"], content['title'] + \" \" + content['description']))\n",
    "    \n",
    "    correlations[\"content_ids_list\"] = correlations[\"content_ids\"].apply(lambda x : x.split())\n",
    "    \n",
    "    all_positive_sample = correlations.explode(\"content_ids_list\")[[\"topic_id\",\"content_ids_list\"]]\n",
    "    all_positive_sample = all_positive_sample.rename(columns={\"topic_id\":\"topics_ids\",\"content_ids_list\":\"content_ids\"})\n",
    "    \n",
    "    all_positive_sample[\"topics_texts\"] = all_positive_sample[\"topics_ids\"].map(topic_text_dict)\n",
    "    all_positive_sample[\"content_texts\"] = all_positive_sample[\"content_ids\"].map(content_text_dict)\n",
    "    all_positive_sample[\"target\"] = 1\n",
    "    \n",
    "    all_positive_sample = all_positive_sample.reset_index(drop=True)\n",
    "    \n",
    "    # 追加するtopic, contentのみを持つlistを生成\n",
    "    all_positive_topic_content = (all_positive_sample[\"topics_ids\"] + all_positive_sample[\"content_ids\"]).tolist()\n",
    "    train_positive = train[train[\"target\"] == 1]\n",
    "    train_positive_topic_content = (train_positive[\"topics_ids\"] + train_positive[\"content_ids\"]).tolist()\n",
    "    add_topic_content = list(set(all_positive_topic_content) - set(train_positive_topic_content))\n",
    "    \n",
    "    # trainにpositive sampleを追加\n",
    "    train = pd.concat([train, all_positive_sample]).drop_duplicates(subset=[\"topics_ids\",\"content_ids\"], keep='first')\n",
    "    train = train.sort_values(\"topics_ids\")\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    return train, add_topic_content\n",
    "\n",
    "train, add_topic_content = add_positive_sample(train, correlations, topics, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67fa349b-7b57-43d6-844e-533dbbeced8a",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"topics_texts\"] = train[\"topics_texts\"].apply(lambda x : \" \".join(x.split()[:128]))\n",
    "train[\"content_texts\"] = train[\"content_texts\"].apply(lambda x : \" \".join(x.split()[:128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cacb8ef-7b40-44a8-9923-e811d089ff1c",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154722"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(add_topic_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27837264",
   "metadata": {
    "papermill": {
     "duration": 0.02252,
     "end_time": "2023-02-11T02:05:30.947474",
     "exception": false,
     "start_time": "2023-02-11T02:05:30.924954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train[:1000]\n",
    "    CFG.epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4205a7c0",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.095627,
     "end_time": "2023-02-11T02:05:33.051735",
     "exception": false,
     "start_time": "2023-02-11T02:05:30.956108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, level_tag_list, category_list, kind_list = merge_cat_info(train, topics, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb705e19",
   "metadata": {
    "papermill": {
     "duration": 0.227458,
     "end_time": "2023-02-11T02:05:33.352932",
     "exception": false,
     "start_time": "2023-02-11T02:05:33.125474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69ad3a19-92b1-4794-9bd7-6daee885cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks/kaggle_lecr/output/ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09133fac",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.251238,
     "end_time": "2023-02-11T02:05:41.664455",
     "exception": false,
     "start_time": "2023-02-11T02:05:33.413217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "CFG.tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model,\n",
    "    additional_special_tokens = level_tag_list + category_list + kind_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc3017c7",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018461,
     "end_time": "2023-02-11T02:05:41.691787",
     "exception": false,
     "start_time": "2023-02-11T02:05:41.673326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[LEVEL0]',\n",
       " '[LEVEL10]',\n",
       " '[LEVEL1]',\n",
       " '[LEVEL2]',\n",
       " '[LEVEL3]',\n",
       " '[LEVEL4]',\n",
       " '[LEVEL5]',\n",
       " '[LEVEL6]',\n",
       " '[LEVEL7]',\n",
       " '[LEVEL8]',\n",
       " '[LEVEL9]',\n",
       " '[CATEGORY_ALIGNED]',\n",
       " '[CATEGORY_SOURCE]',\n",
       " '[CATEGORY_SUPPLEMENTAL]',\n",
       " '[KIND_AUDIO]',\n",
       " '[KIND_DOCUMENT]',\n",
       " '[KIND_EXERCISE]',\n",
       " '[KIND_HTML5]',\n",
       " '[KIND_VIDEO]']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.tokenizer.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b490a510-9e68-4203-b3a1-9bd5ce3c787a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# categoryがsourceのnegativeデータを減らし、計算時間を短くする\n",
    "# train[\"is_category_source\"] = train[\"topics_texts\"].str.contains(\"CATEGORY_SOURCE\")\n",
    "# train = train[~(train[\"is_category_source\"] & (train[\"target\"] == 0))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4871bf1d-8673-4cec-8472-7daa58e3e865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 計算を終わらせるため、行を減らす\n",
    "# if not CFG.debug:\n",
    "#     train = train.sample(200000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e5a3ce5",
   "metadata": {
    "papermill": {
     "duration": 24.616901,
     "end_time": "2023-02-11T02:06:06.316153",
     "exception": false,
     "start_time": "2023-02-11T02:05:41.699252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CV split\n",
    "train = cv_split(train, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "234ea5e9-9f5c-4e84-a884-de3ab5d0cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = train[[\"topics_ids\",\"fold\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be63cf4e-0915-42ed-b32b-9adf32adb3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.drop_duplicates().to_csv(\"topics_ids_fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb66dca3-cbb8-4d3e-a012-eb589fc18c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_list = train[train[\"fold\"] == 0][\"topics_ids\"].unique().tolist()\n",
    "with open(f\"{OUTPUT_DIR}/fold_0_topics_ids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fold0_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "287e8991-6d5a-470d-9459-2cc95718db13",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    156221\n",
      "1    154330\n",
      "4    153929\n",
      "3    152999\n",
      "2    152413\n",
      "Name: fold, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"fold\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "494577d4-2513-465c-938c-c4d635829e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84d901da-9881-4008-8a1d-53655a9722ec",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    489973\n",
       "1    279919\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07e9b843",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 81.097871,
     "end_time": "2023-02-11T02:07:27.589260",
     "exception": false,
     "start_time": "2023-02-11T02:06:06.491389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d53ee6588241a2b4c1e8b71d3b14b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/769892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len: 512\n"
     ]
    }
   ],
   "source": [
    "# Get max length\n",
    "get_max_length(train, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "896807cf-cf68-42f9-aca1-118b255065e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5253160",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 17391.060041,
     "end_time": "2023-02-11T06:57:18.656824",
     "exception": false,
     "start_time": "2023-02-11T02:07:27.596783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "========== fold: 0 training ==========\n",
      "Epoch: [1][0/19177] Elapsed 0m 1s (remain 387m 19s) Loss: 0.6943(0.6943) Grad: 1.0083  LR: 0.00000000  \n",
      "Epoch: [1][500/19177] Elapsed 0m 52s (remain 32m 26s) Loss: 0.6765(0.6838) Grad: 0.6482  LR: 0.00000052  \n",
      "Epoch: [1][1000/19177] Elapsed 1m 44s (remain 31m 33s) Loss: 0.6467(0.6620) Grad: 1.6664  LR: 0.00000104  \n",
      "Epoch: [1][1500/19177] Elapsed 2m 36s (remain 30m 48s) Loss: 0.5810(0.6447) Grad: 3.2006  LR: 0.00000157  \n",
      "Epoch: [1][2000/19177] Elapsed 3m 27s (remain 29m 42s) Loss: 0.4958(0.6256) Grad: 4.2187  LR: 0.00000209  \n",
      "Epoch: [1][2500/19177] Elapsed 4m 17s (remain 28m 34s) Loss: 0.4446(0.6064) Grad: 5.4359  LR: 0.00000261  \n",
      "Epoch: [1][3000/19177] Elapsed 5m 8s (remain 27m 42s) Loss: 0.5081(0.5868) Grad: 8.8258  LR: 0.00000313  \n",
      "Epoch: [1][3500/19177] Elapsed 5m 58s (remain 26m 47s) Loss: 0.6184(0.5705) Grad: 9.7548  LR: 0.00000365  \n",
      "Epoch: [1][4000/19177] Elapsed 6m 49s (remain 25m 54s) Loss: 0.3567(0.5565) Grad: 7.9310  LR: 0.00000417  \n",
      "Epoch: [1][4500/19177] Elapsed 7m 41s (remain 25m 6s) Loss: 0.3154(0.5445) Grad: 7.5538  LR: 0.00000469  \n",
      "Epoch: [1][5000/19177] Elapsed 8m 33s (remain 24m 15s) Loss: 0.3285(0.5333) Grad: 13.8971  LR: 0.00000522  \n",
      "Epoch: [1][5500/19177] Elapsed 9m 24s (remain 23m 24s) Loss: 0.4521(0.5232) Grad: 6.6886  LR: 0.00000574  \n",
      "Epoch: [1][6000/19177] Elapsed 10m 18s (remain 22m 38s) Loss: 0.3042(0.5146) Grad: 7.0425  LR: 0.00000626  \n",
      "Epoch: [1][6500/19177] Elapsed 11m 9s (remain 21m 46s) Loss: 0.4759(0.5063) Grad: 7.1396  LR: 0.00000678  \n",
      "Epoch: [1][7000/19177] Elapsed 12m 1s (remain 20m 55s) Loss: 0.4530(0.4990) Grad: 8.2371  LR: 0.00000730  \n",
      "Epoch: [1][7500/19177] Elapsed 12m 53s (remain 20m 4s) Loss: 0.4532(0.4923) Grad: 6.7481  LR: 0.00000782  \n",
      "Epoch: [1][8000/19177] Elapsed 13m 45s (remain 19m 13s) Loss: 0.3460(0.4861) Grad: 3.6236  LR: 0.00000834  \n",
      "Epoch: [1][8500/19177] Elapsed 14m 37s (remain 18m 22s) Loss: 0.3693(0.4801) Grad: 7.2486  LR: 0.00000887  \n",
      "Epoch: [1][9000/19177] Elapsed 15m 28s (remain 17m 29s) Loss: 0.3894(0.4745) Grad: 6.9122  LR: 0.00000939  \n",
      "Epoch: [1][9500/19177] Elapsed 16m 19s (remain 16m 37s) Loss: 0.4461(0.4694) Grad: 8.1205  LR: 0.00000991  \n",
      "Epoch: [1][10000/19177] Elapsed 17m 8s (remain 15m 43s) Loss: 0.1907(0.4644) Grad: 5.5508  LR: 0.00001000  \n",
      "Epoch: [1][10500/19177] Elapsed 17m 59s (remain 14m 51s) Loss: 0.2765(0.4595) Grad: 4.1163  LR: 0.00001000  \n",
      "Epoch: [1][11000/19177] Elapsed 18m 50s (remain 14m 0s) Loss: 0.3153(0.4548) Grad: 5.8409  LR: 0.00000999  \n",
      "Epoch: [1][11500/19177] Elapsed 19m 40s (remain 13m 8s) Loss: 0.3163(0.4506) Grad: 7.5838  LR: 0.00000999  \n",
      "Epoch: [1][12000/19177] Elapsed 20m 30s (remain 12m 15s) Loss: 0.3177(0.4466) Grad: 5.1561  LR: 0.00000998  \n",
      "Epoch: [1][12500/19177] Elapsed 21m 19s (remain 11m 23s) Loss: 0.3473(0.4428) Grad: 5.7884  LR: 0.00000997  \n",
      "Epoch: [1][13000/19177] Elapsed 22m 9s (remain 10m 31s) Loss: 0.6080(0.4393) Grad: 8.8210  LR: 0.00000996  \n",
      "Epoch: [1][13500/19177] Elapsed 23m 0s (remain 9m 40s) Loss: 0.2353(0.4358) Grad: 4.9403  LR: 0.00000995  \n",
      "Epoch: [1][14000/19177] Elapsed 23m 53s (remain 8m 49s) Loss: 0.5133(0.4324) Grad: 8.5519  LR: 0.00000994  \n",
      "Epoch: [1][15500/19177] Elapsed 26m 24s (remain 6m 15s) Loss: 0.1342(0.4234) Grad: 4.2686  LR: 0.00000988  \n",
      "Epoch: [1][16000/19177] Elapsed 27m 17s (remain 5m 24s) Loss: 0.4182(0.4205) Grad: 7.1391  LR: 0.00000986  \n",
      "Epoch: [1][16500/19177] Elapsed 28m 10s (remain 4m 34s) Loss: 0.4305(0.4178) Grad: 17.4019  LR: 0.00000984  \n",
      "Epoch: [1][17000/19177] Elapsed 29m 2s (remain 3m 43s) Loss: 0.5062(0.4149) Grad: 12.9365  LR: 0.00000982  \n",
      "Epoch: [1][17500/19177] Elapsed 29m 53s (remain 2m 51s) Loss: 0.4128(0.4123) Grad: 5.4526  LR: 0.00000979  \n",
      "Epoch: [1][18000/19177] Elapsed 30m 46s (remain 2m 0s) Loss: 0.2632(0.4097) Grad: 6.1945  LR: 0.00000977  \n",
      "Epoch: [1][18500/19177] Elapsed 31m 36s (remain 1m 9s) Loss: 0.2663(0.4073) Grad: 5.0903  LR: 0.00000974  \n",
      "Epoch: [1][19000/19177] Elapsed 32m 26s (remain 0m 18s) Loss: 0.2992(0.4051) Grad: 7.4642  LR: 0.00000971  \n",
      "Epoch: [1][19176/19177] Elapsed 32m 45s (remain 0m 0s) Loss: 0.2215(0.4042) Grad: 3.1799  LR: 0.00000970  \n",
      "EVAL: [0/1590] Elapsed 0m 0s (remain 5m 57s) Loss: 0.1912(0.1912) \n",
      "EVAL: [500/1590] Elapsed 0m 7s (remain 0m 16s) Loss: 0.3734(0.3432) \n",
      "EVAL: [1000/1590] Elapsed 0m 15s (remain 0m 8s) Loss: 0.3089(0.3467) \n",
      "EVAL: [1500/1590] Elapsed 0m 22s (remain 0m 1s) Loss: 0.3693(0.3454) \n",
      "EVAL: [1589/1590] Elapsed 0m 24s (remain 0m 0s) Loss: 0.4980(0.3458) \n",
      "Epoch 1 - avg_train_loss: 0.4042  avg_val_loss: 0.3458  time: 2017s\n",
      "Epoch 1 - Score: 0.3785 - Threshold: 0.07300\n",
      "Epoch 1 - Save Best Score: 0.3785 Model\n",
      "Epoch: [2][0/19177] Elapsed 0m 0s (remain 96m 33s) Loss: 0.2634(0.2634) Grad: 4.2304  LR: 0.00000970  \n",
      "Epoch: [2][500/19177] Elapsed 0m 52s (remain 32m 27s) Loss: 0.5668(0.3006) Grad: 10.4211  LR: 0.00000967  \n",
      "Epoch: [2][1000/19177] Elapsed 1m 41s (remain 30m 48s) Loss: 0.1521(0.3012) Grad: 3.7565  LR: 0.00000963  \n",
      "Epoch: [2][1500/19177] Elapsed 2m 32s (remain 29m 56s) Loss: 0.2974(0.2999) Grad: 11.5426  LR: 0.00000960  \n",
      "Epoch: [2][2000/19177] Elapsed 3m 23s (remain 29m 8s) Loss: 0.3815(0.2998) Grad: 10.4151  LR: 0.00000956  \n",
      "Epoch: [2][2500/19177] Elapsed 4m 13s (remain 28m 11s) Loss: 0.2047(0.2987) Grad: 5.9735  LR: 0.00000952  \n",
      "Epoch: [2][3000/19177] Elapsed 5m 5s (remain 27m 29s) Loss: 0.4456(0.2977) Grad: 9.5410  LR: 0.00000948  \n",
      "Epoch: [2][3500/19177] Elapsed 5m 58s (remain 26m 43s) Loss: 0.3357(0.2973) Grad: 4.8468  LR: 0.00000944  \n",
      "Epoch: [2][5000/19177] Elapsed 8m 30s (remain 24m 6s) Loss: 0.2229(0.2961) Grad: 4.8500  LR: 0.00000931  \n",
      "Epoch: [2][5500/19177] Elapsed 9m 22s (remain 23m 19s) Loss: 0.2763(0.2955) Grad: 8.7020  LR: 0.00000926  \n",
      "Epoch: [2][6000/19177] Elapsed 10m 15s (remain 22m 31s) Loss: 0.2312(0.2951) Grad: 5.6834  LR: 0.00000922  \n",
      "Epoch: [2][6500/19177] Elapsed 11m 7s (remain 21m 42s) Loss: 0.5077(0.2951) Grad: 7.8464  LR: 0.00000917  \n",
      "Epoch: [2][7000/19177] Elapsed 11m 58s (remain 20m 50s) Loss: 0.3158(0.2944) Grad: 11.9353  LR: 0.00000912  \n",
      "Epoch: [2][7500/19177] Elapsed 12m 51s (remain 20m 0s) Loss: 0.3623(0.2941) Grad: 5.8032  LR: 0.00000906  \n",
      "Epoch: [2][8000/19177] Elapsed 13m 43s (remain 19m 10s) Loss: 0.1760(0.2937) Grad: 8.7297  LR: 0.00000901  \n",
      "Epoch: [2][8500/19177] Elapsed 14m 35s (remain 18m 19s) Loss: 0.3885(0.2932) Grad: 13.5392  LR: 0.00000895  \n",
      "Epoch: [2][9000/19177] Elapsed 15m 27s (remain 17m 28s) Loss: 0.1784(0.2926) Grad: 5.0588  LR: 0.00000890  \n",
      "Epoch: [2][9500/19177] Elapsed 16m 20s (remain 16m 38s) Loss: 0.3916(0.2919) Grad: 15.3825  LR: 0.00000884  \n",
      "Epoch: [2][10000/19177] Elapsed 17m 13s (remain 15m 48s) Loss: 0.3755(0.2915) Grad: 10.3319  LR: 0.00000878  \n",
      "Epoch: [2][10500/19177] Elapsed 18m 4s (remain 14m 55s) Loss: 0.3260(0.2908) Grad: 8.4674  LR: 0.00000872  \n",
      "Epoch: [2][11000/19177] Elapsed 18m 54s (remain 14m 3s) Loss: 0.3257(0.2904) Grad: 6.6679  LR: 0.00000866  \n",
      "Epoch: [2][11500/19177] Elapsed 19m 45s (remain 13m 10s) Loss: 0.2844(0.2899) Grad: 13.3256  LR: 0.00000860  \n",
      "Epoch: [2][12000/19177] Elapsed 20m 35s (remain 12m 19s) Loss: 0.1625(0.2894) Grad: 4.8446  LR: 0.00000853  \n",
      "Epoch: [2][12500/19177] Elapsed 21m 27s (remain 11m 27s) Loss: 0.2495(0.2890) Grad: 8.1923  LR: 0.00000847  \n",
      "Epoch: [2][13000/19177] Elapsed 22m 17s (remain 10m 35s) Loss: 0.2732(0.2884) Grad: 7.7789  LR: 0.00000840  \n",
      "Epoch: [2][13500/19177] Elapsed 23m 6s (remain 9m 43s) Loss: 0.2666(0.2878) Grad: 6.0327  LR: 0.00000834  \n",
      "Epoch: [2][14000/19177] Elapsed 23m 58s (remain 8m 51s) Loss: 0.2288(0.2873) Grad: 6.3791  LR: 0.00000827  \n",
      "Epoch: [2][14500/19177] Elapsed 24m 48s (remain 7m 59s) Loss: 0.1665(0.2868) Grad: 4.5398  LR: 0.00000820  \n",
      "Epoch: [2][15000/19177] Elapsed 25m 39s (remain 7m 8s) Loss: 0.2132(0.2864) Grad: 5.2788  LR: 0.00000813  \n",
      "Epoch: [2][15500/19177] Elapsed 26m 31s (remain 6m 17s) Loss: 0.3154(0.2859) Grad: 7.4015  LR: 0.00000806  \n",
      "Epoch: [2][16000/19177] Elapsed 27m 22s (remain 5m 26s) Loss: 0.2646(0.2852) Grad: 4.5738  LR: 0.00000798  \n",
      "Epoch: [2][16500/19177] Elapsed 28m 11s (remain 4m 34s) Loss: 0.2879(0.2847) Grad: 6.3391  LR: 0.00000791  \n",
      "Epoch: [2][17000/19177] Elapsed 29m 1s (remain 3m 42s) Loss: 0.3037(0.2843) Grad: 4.8292  LR: 0.00000783  \n",
      "Epoch: [2][17500/19177] Elapsed 29m 53s (remain 2m 51s) Loss: 0.2840(0.2839) Grad: 4.6832  LR: 0.00000776  \n",
      "Epoch: [2][18000/19177] Elapsed 30m 43s (remain 2m 0s) Loss: 0.2391(0.2835) Grad: 6.1711  LR: 0.00000768  \n",
      "Epoch: [2][18500/19177] Elapsed 31m 35s (remain 1m 9s) Loss: 0.3021(0.2831) Grad: 11.7320  LR: 0.00000761  \n",
      "Epoch: [2][19000/19177] Elapsed 32m 26s (remain 0m 18s) Loss: 0.2056(0.2825) Grad: 6.7985  LR: 0.00000753  \n",
      "Epoch: [2][19176/19177] Elapsed 32m 44s (remain 0m 0s) Loss: 0.2109(0.2824) Grad: 4.3930  LR: 0.00000750  \n",
      "EVAL: [0/1590] Elapsed 0m 0s (remain 6m 0s) Loss: 0.2302(0.2302) \n",
      "EVAL: [500/1590] Elapsed 0m 7s (remain 0m 16s) Loss: 0.3684(0.3385) \n",
      "EVAL: [1000/1590] Elapsed 0m 15s (remain 0m 8s) Loss: 0.2618(0.3421) \n",
      "EVAL: [1500/1590] Elapsed 0m 22s (remain 0m 1s) Loss: 0.3786(0.3375) \n",
      "EVAL: [1589/1590] Elapsed 0m 24s (remain 0m 0s) Loss: 0.3980(0.3380) \n",
      "Epoch 2 - avg_train_loss: 0.2824  avg_val_loss: 0.3380  time: 2015s\n",
      "Epoch 2 - Score: 0.3928 - Threshold: 0.09400\n",
      "Epoch 2 - Save Best Score: 0.3928 Model\n",
      "Epoch: [3][0/19177] Elapsed 0m 0s (remain 104m 55s) Loss: 0.1770(0.1770) Grad: 4.4403  LR: 0.00000750  \n",
      "Epoch: [3][500/19177] Elapsed 0m 52s (remain 32m 19s) Loss: 0.2115(0.2342) Grad: 5.1822  LR: 0.00000742  \n",
      "Epoch: [3][1000/19177] Elapsed 1m 43s (remain 31m 17s) Loss: 0.1537(0.2312) Grad: 5.5418  LR: 0.00000734  \n",
      "Epoch: [3][1500/19177] Elapsed 2m 33s (remain 30m 8s) Loss: 0.0270(0.2320) Grad: 1.1895  LR: 0.00000726  \n",
      "Epoch: [3][2000/19177] Elapsed 3m 22s (remain 28m 59s) Loss: 0.2074(0.2318) Grad: 8.6290  LR: 0.00000718  \n",
      "Epoch: [3][2500/19177] Elapsed 4m 15s (remain 28m 21s) Loss: 0.1593(0.2327) Grad: 7.9895  LR: 0.00000710  \n",
      "Epoch: [3][3000/19177] Elapsed 5m 7s (remain 27m 35s) Loss: 0.1489(0.2326) Grad: 4.8640  LR: 0.00000701  \n",
      "Epoch: [3][3500/19177] Elapsed 5m 59s (remain 26m 49s) Loss: 0.2094(0.2326) Grad: 9.1095  LR: 0.00000693  \n",
      "Epoch: [3][4000/19177] Elapsed 6m 48s (remain 25m 51s) Loss: 0.1704(0.2331) Grad: 6.8570  LR: 0.00000685  \n",
      "Epoch: [3][4500/19177] Elapsed 7m 37s (remain 24m 53s) Loss: 0.0757(0.2330) Grad: 4.0555  LR: 0.00000676  \n",
      "Epoch: [3][5000/19177] Elapsed 8m 30s (remain 24m 5s) Loss: 0.2614(0.2333) Grad: 8.9842  LR: 0.00000667  \n",
      "Epoch: [3][5500/19177] Elapsed 9m 21s (remain 23m 15s) Loss: 0.1441(0.2331) Grad: 5.3701  LR: 0.00000659  \n",
      "Epoch: [3][6000/19177] Elapsed 10m 12s (remain 22m 24s) Loss: 0.2556(0.2328) Grad: 7.7381  LR: 0.00000650  \n",
      "Epoch: [3][6500/19177] Elapsed 11m 5s (remain 21m 36s) Loss: 0.1664(0.2328) Grad: 9.7234  LR: 0.00000642  \n",
      "Epoch: [3][7000/19177] Elapsed 11m 56s (remain 20m 46s) Loss: 0.2583(0.2329) Grad: 8.0087  LR: 0.00000633  \n",
      "Epoch: [3][7500/19177] Elapsed 12m 47s (remain 19m 55s) Loss: 0.2024(0.2329) Grad: 9.6636  LR: 0.00000624  \n",
      "Epoch: [3][8000/19177] Elapsed 13m 38s (remain 19m 3s) Loss: 0.2207(0.2328) Grad: 5.2686  LR: 0.00000615  \n",
      "Epoch: [3][8500/19177] Elapsed 14m 29s (remain 18m 12s) Loss: 0.2272(0.2324) Grad: 5.7268  LR: 0.00000606  \n",
      "Epoch: [3][9000/19177] Elapsed 15m 21s (remain 17m 21s) Loss: 0.1933(0.2321) Grad: 6.9373  LR: 0.00000597  \n",
      "Epoch: [3][9500/19177] Elapsed 16m 12s (remain 16m 30s) Loss: 0.2823(0.2318) Grad: 13.0893  LR: 0.00000588  \n",
      "Epoch: [3][10000/19177] Elapsed 17m 4s (remain 15m 40s) Loss: 0.0821(0.2317) Grad: 3.5904  LR: 0.00000579  \n",
      "Epoch: [3][10500/19177] Elapsed 17m 55s (remain 14m 48s) Loss: 0.2535(0.2317) Grad: 11.4038  LR: 0.00000570  \n",
      "Epoch: [3][11000/19177] Elapsed 18m 48s (remain 13m 58s) Loss: 0.0979(0.2313) Grad: 3.8273  LR: 0.00000561  \n",
      "Epoch: [3][11500/19177] Elapsed 19m 40s (remain 13m 7s) Loss: 0.2526(0.2312) Grad: 5.1477  LR: 0.00000552  \n",
      "Epoch: [3][12000/19177] Elapsed 20m 30s (remain 12m 15s) Loss: 0.3024(0.2309) Grad: 9.4135  LR: 0.00000543  \n",
      "Epoch: [3][12500/19177] Elapsed 21m 21s (remain 11m 24s) Loss: 0.2180(0.2306) Grad: 6.4149  LR: 0.00000534  \n",
      "Epoch: [3][13000/19177] Elapsed 22m 12s (remain 10m 33s) Loss: 0.2190(0.2303) Grad: 14.5078  LR: 0.00000525  \n",
      "Epoch: [3][13500/19177] Elapsed 23m 4s (remain 9m 42s) Loss: 0.3728(0.2299) Grad: 9.8480  LR: 0.00000516  \n",
      "Epoch: [3][14000/19177] Elapsed 23m 56s (remain 8m 51s) Loss: 0.1182(0.2297) Grad: 6.3136  LR: 0.00000507  \n",
      "Epoch: [3][14500/19177] Elapsed 24m 48s (remain 7m 59s) Loss: 0.0607(0.2293) Grad: 4.1355  LR: 0.00000498  \n",
      "Epoch: [3][15000/19177] Elapsed 25m 40s (remain 7m 8s) Loss: 0.3202(0.2289) Grad: 13.5158  LR: 0.00000489  \n",
      "Epoch: [3][15500/19177] Elapsed 26m 28s (remain 6m 16s) Loss: 0.3127(0.2286) Grad: 14.4305  LR: 0.00000480  \n",
      "Epoch: [3][16000/19177] Elapsed 27m 20s (remain 5m 25s) Loss: 0.3759(0.2285) Grad: 10.6445  LR: 0.00000471  \n",
      "Epoch: [3][16500/19177] Elapsed 28m 10s (remain 4m 34s) Loss: 0.1916(0.2282) Grad: 14.1939  LR: 0.00000461  \n",
      "Epoch: [3][17000/19177] Elapsed 28m 59s (remain 3m 42s) Loss: 0.2074(0.2283) Grad: 8.7548  LR: 0.00000452  \n",
      "Epoch: [3][17500/19177] Elapsed 29m 50s (remain 2m 51s) Loss: 0.2308(0.2280) Grad: 8.7635  LR: 0.00000443  \n",
      "Epoch: [3][18000/19177] Elapsed 30m 42s (remain 2m 0s) Loss: 0.1181(0.2277) Grad: 6.4916  LR: 0.00000434  \n",
      "Epoch: [3][18500/19177] Elapsed 31m 35s (remain 1m 9s) Loss: 0.4659(0.2274) Grad: 19.4144  LR: 0.00000425  \n",
      "Epoch: [3][19000/19177] Elapsed 32m 26s (remain 0m 18s) Loss: 0.1777(0.2272) Grad: 6.8114  LR: 0.00000416  \n",
      "Epoch: [3][19176/19177] Elapsed 32m 43s (remain 0m 0s) Loss: 0.2791(0.2271) Grad: 14.3072  LR: 0.00000413  \n",
      "EVAL: [0/1590] Elapsed 0m 0s (remain 5m 46s) Loss: 0.1750(0.1750) \n",
      "EVAL: [500/1590] Elapsed 0m 7s (remain 0m 16s) Loss: 0.4227(0.3443) \n",
      "EVAL: [1000/1590] Elapsed 0m 15s (remain 0m 8s) Loss: 0.0663(0.3464) \n",
      "EVAL: [1500/1590] Elapsed 0m 22s (remain 0m 1s) Loss: 0.3990(0.3396) \n",
      "EVAL: [1589/1590] Elapsed 0m 23s (remain 0m 0s) Loss: 0.2795(0.3405) \n",
      "Epoch 3 - avg_train_loss: 0.2271  avg_val_loss: 0.3405  time: 2013s\n",
      "Epoch 3 - Score: 0.4008 - Threshold: 0.05400\n",
      "Epoch 3 - Save Best Score: 0.4008 Model\n",
      "Epoch: [4][0/19177] Elapsed 0m 0s (remain 101m 1s) Loss: 0.0796(0.0796) Grad: 14.8112  LR: 0.00000413  \n",
      "Epoch: [4][500/19177] Elapsed 0m 53s (remain 33m 8s) Loss: 0.1591(0.1848) Grad: 9.2381  LR: 0.00000404  \n",
      "Epoch: [4][1000/19177] Elapsed 1m 44s (remain 31m 37s) Loss: 0.1196(0.1843) Grad: 9.0317  LR: 0.00000395  \n",
      "Epoch: [4][1500/19177] Elapsed 2m 35s (remain 30m 33s) Loss: 0.2254(0.1841) Grad: 14.7037  LR: 0.00000386  \n",
      "Epoch: [4][2000/19177] Elapsed 3m 27s (remain 29m 40s) Loss: 0.2060(0.1843) Grad: 11.3653  LR: 0.00000378  \n",
      "Epoch: [4][2500/19177] Elapsed 4m 20s (remain 28m 54s) Loss: 0.1819(0.1835) Grad: 16.3550  LR: 0.00000369  \n",
      "Epoch: [4][3000/19177] Elapsed 5m 10s (remain 27m 52s) Loss: 0.2651(0.1834) Grad: 16.1421  LR: 0.00000360  \n",
      "Epoch: [4][3500/19177] Elapsed 5m 59s (remain 26m 50s) Loss: 0.2923(0.1835) Grad: 10.5672  LR: 0.00000351  \n",
      "Epoch: [4][4000/19177] Elapsed 6m 51s (remain 26m 2s) Loss: 0.2891(0.1841) Grad: 12.8888  LR: 0.00000343  \n",
      "Epoch: [4][4500/19177] Elapsed 7m 42s (remain 25m 7s) Loss: 0.2308(0.1839) Grad: 9.3717  LR: 0.00000334  \n",
      "Epoch: [4][5000/19177] Elapsed 8m 34s (remain 24m 18s) Loss: 0.1637(0.1835) Grad: 11.9716  LR: 0.00000325  \n",
      "Epoch: [4][5500/19177] Elapsed 9m 26s (remain 23m 28s) Loss: 0.2874(0.1835) Grad: 20.4604  LR: 0.00000317  \n",
      "Epoch: [4][6000/19177] Elapsed 10m 16s (remain 22m 34s) Loss: 0.2938(0.1838) Grad: 15.0979  LR: 0.00000309  \n",
      "Epoch: [4][6500/19177] Elapsed 11m 8s (remain 21m 43s) Loss: 0.2015(0.1835) Grad: 12.6340  LR: 0.00000300  \n",
      "Epoch: [4][7000/19177] Elapsed 12m 0s (remain 20m 52s) Loss: 0.2522(0.1833) Grad: 11.7397  LR: 0.00000292  \n",
      "Epoch: [4][7500/19177] Elapsed 12m 51s (remain 20m 0s) Loss: 0.1903(0.1834) Grad: 6.2403  LR: 0.00000284  \n",
      "Epoch: [4][8000/19177] Elapsed 13m 43s (remain 19m 10s) Loss: 0.3525(0.1834) Grad: 21.8215  LR: 0.00000275  \n",
      "Epoch: [4][8500/19177] Elapsed 14m 34s (remain 18m 17s) Loss: 0.0964(0.1832) Grad: 8.2892  LR: 0.00000267  \n",
      "Epoch: [4][9000/19177] Elapsed 15m 25s (remain 17m 26s) Loss: 0.1129(0.1830) Grad: 5.2170  LR: 0.00000259  \n",
      "Epoch: [4][9500/19177] Elapsed 16m 17s (remain 16m 35s) Loss: 0.1298(0.1832) Grad: 18.8136  LR: 0.00000251  \n",
      "Epoch: [4][11500/19177] Elapsed 19m 42s (remain 13m 9s) Loss: 0.2425(0.1829) Grad: 16.1812  LR: 0.00000220  \n",
      "Epoch: [4][12000/19177] Elapsed 20m 32s (remain 12m 17s) Loss: 0.1872(0.1828) Grad: 10.4948  LR: 0.00000213  \n",
      "Epoch: [4][12500/19177] Elapsed 21m 24s (remain 11m 25s) Loss: 0.1467(0.1827) Grad: 13.9789  LR: 0.00000206  \n",
      "Epoch: [4][13000/19177] Elapsed 22m 15s (remain 10m 34s) Loss: 0.1306(0.1826) Grad: 8.5666  LR: 0.00000198  \n",
      "Epoch: [4][13500/19177] Elapsed 23m 7s (remain 9m 43s) Loss: 0.1051(0.1825) Grad: 19.7392  LR: 0.00000191  \n",
      "Epoch: [4][14000/19177] Elapsed 23m 57s (remain 8m 51s) Loss: 0.0293(0.1824) Grad: 2.5262  LR: 0.00000184  \n",
      "Epoch: [4][14500/19177] Elapsed 24m 47s (remain 7m 59s) Loss: 0.1662(0.1823) Grad: 7.5943  LR: 0.00000177  \n",
      "Epoch: [4][15000/19177] Elapsed 25m 37s (remain 7m 8s) Loss: 0.1091(0.1822) Grad: 10.4771  LR: 0.00000170  \n",
      "Epoch: [4][15500/19177] Elapsed 26m 29s (remain 6m 16s) Loss: 0.0636(0.1823) Grad: 4.9626  LR: 0.00000163  \n",
      "Epoch: [4][16000/19177] Elapsed 27m 20s (remain 5m 25s) Loss: 0.0877(0.1821) Grad: 16.6641  LR: 0.00000157  \n",
      "Epoch: [4][16500/19177] Elapsed 28m 10s (remain 4m 34s) Loss: 0.0999(0.1820) Grad: 7.7788  LR: 0.00000150  \n",
      "Epoch: [4][17000/19177] Elapsed 29m 3s (remain 3m 43s) Loss: 0.2875(0.1817) Grad: 18.2822  LR: 0.00000144  \n",
      "Epoch: [4][17500/19177] Elapsed 29m 54s (remain 2m 51s) Loss: 0.0732(0.1813) Grad: 8.6194  LR: 0.00000137  \n",
      "Epoch: [4][18000/19177] Elapsed 30m 45s (remain 2m 0s) Loss: 0.3152(0.1812) Grad: 15.4176  LR: 0.00000131  \n",
      "Epoch: [4][18500/19177] Elapsed 31m 36s (remain 1m 9s) Loss: 0.1426(0.1812) Grad: 9.2721  LR: 0.00000125  \n",
      "Epoch: [4][19000/19177] Elapsed 32m 27s (remain 0m 18s) Loss: 0.2422(0.1810) Grad: 20.1997  LR: 0.00000119  \n",
      "Epoch: [4][19176/19177] Elapsed 32m 46s (remain 0m 0s) Loss: 0.1754(0.1810) Grad: 14.4053  LR: 0.00000117  \n",
      "EVAL: [0/1590] Elapsed 0m 0s (remain 6m 4s) Loss: 0.2337(0.2337) \n",
      "EVAL: [500/1590] Elapsed 0m 7s (remain 0m 16s) Loss: 0.4397(0.3614) \n",
      "EVAL: [1000/1590] Elapsed 0m 15s (remain 0m 8s) Loss: 0.0518(0.3689) \n",
      "EVAL: [1500/1590] Elapsed 0m 22s (remain 0m 1s) Loss: 0.4119(0.3631) \n",
      "EVAL: [1589/1590] Elapsed 0m 24s (remain 0m 0s) Loss: 0.3121(0.3638) \n",
      "Epoch 4 - avg_train_loss: 0.1810  avg_val_loss: 0.3638  time: 2015s\n",
      "Epoch 4 - Score: 0.4048 - Threshold: 0.04100\n",
      "Epoch 4 - Save Best Score: 0.4048 Model\n",
      "Epoch: [5][0/19177] Elapsed 0m 0s (remain 107m 46s) Loss: 0.2438(0.2438) Grad: 10.5451  LR: 0.00000117  \n",
      "Epoch: [5][1500/19177] Elapsed 2m 34s (remain 30m 19s) Loss: 0.3206(0.1480) Grad: 19.2874  LR: 0.00000100  \n",
      "Epoch: [5][2000/19177] Elapsed 3m 26s (remain 29m 31s) Loss: 0.0885(0.1498) Grad: 8.7962  LR: 0.00000095  \n",
      "Epoch: [5][2500/19177] Elapsed 4m 18s (remain 28m 44s) Loss: 0.1928(0.1508) Grad: 11.8994  LR: 0.00000089  \n",
      "Epoch: [5][3000/19177] Elapsed 5m 10s (remain 27m 55s) Loss: 0.1977(0.1498) Grad: 11.9679  LR: 0.00000084  \n",
      "Epoch: [5][3500/19177] Elapsed 6m 1s (remain 26m 56s) Loss: 0.1092(0.1501) Grad: 8.2962  LR: 0.00000079  \n",
      "Epoch: [5][4000/19177] Elapsed 6m 51s (remain 26m 1s) Loss: 0.1522(0.1500) Grad: 15.6574  LR: 0.00000074  \n",
      "Epoch: [5][4500/19177] Elapsed 7m 41s (remain 25m 4s) Loss: 0.1259(0.1501) Grad: 13.0392  LR: 0.00000070  \n",
      "Epoch: [5][5000/19177] Elapsed 8m 31s (remain 24m 9s) Loss: 0.2883(0.1499) Grad: 23.8980  LR: 0.00000065  \n",
      "Epoch: [5][5500/19177] Elapsed 9m 22s (remain 23m 18s) Loss: 0.1371(0.1502) Grad: 10.5026  LR: 0.00000061  \n",
      "Epoch: [5][6000/19177] Elapsed 10m 13s (remain 22m 27s) Loss: 0.0526(0.1499) Grad: 10.4217  LR: 0.00000056  \n",
      "Epoch: [5][6500/19177] Elapsed 11m 4s (remain 21m 35s) Loss: 0.0442(0.1500) Grad: 5.3367  LR: 0.00000052  \n",
      "Epoch: [5][7000/19177] Elapsed 11m 56s (remain 20m 46s) Loss: 0.0755(0.1498) Grad: 9.8132  LR: 0.00000048  \n",
      "Epoch: [5][7500/19177] Elapsed 12m 47s (remain 19m 54s) Loss: 0.0830(0.1501) Grad: 6.2167  LR: 0.00000044  \n",
      "Epoch: [5][8000/19177] Elapsed 13m 38s (remain 19m 3s) Loss: 0.2252(0.1503) Grad: 18.5588  LR: 0.00000041  \n",
      "Epoch: [5][8500/19177] Elapsed 14m 29s (remain 18m 11s) Loss: 0.1614(0.1502) Grad: 15.2783  LR: 0.00000037  \n",
      "Epoch: [5][9000/19177] Elapsed 15m 18s (remain 17m 18s) Loss: 0.2915(0.1502) Grad: 14.2475  LR: 0.00000034  \n",
      "Epoch: [5][9500/19177] Elapsed 16m 9s (remain 16m 27s) Loss: 0.0567(0.1504) Grad: 10.9519  LR: 0.00000031  \n",
      "Epoch: [5][11500/19177] Elapsed 19m 34s (remain 13m 4s) Loss: 0.1386(0.1508) Grad: 12.4924  LR: 0.00000019  \n",
      "Epoch: [5][12000/19177] Elapsed 20m 26s (remain 12m 13s) Loss: 0.0817(0.1510) Grad: 5.7797  LR: 0.00000017  \n",
      "Epoch: [5][12500/19177] Elapsed 21m 17s (remain 11m 22s) Loss: 0.0589(0.1509) Grad: 13.6936  LR: 0.00000015  \n",
      "Epoch: [5][13000/19177] Elapsed 22m 9s (remain 10m 31s) Loss: 0.1109(0.1511) Grad: 15.8427  LR: 0.00000013  \n",
      "Epoch: [5][13500/19177] Elapsed 22m 59s (remain 9m 40s) Loss: 0.1756(0.1509) Grad: 11.0623  LR: 0.00000011  \n",
      "Epoch: [5][14000/19177] Elapsed 23m 49s (remain 8m 48s) Loss: 0.1219(0.1508) Grad: 14.5899  LR: 0.00000009  \n",
      "Epoch: [5][14500/19177] Elapsed 24m 43s (remain 7m 58s) Loss: 0.1552(0.1509) Grad: 15.1239  LR: 0.00000007  \n",
      "Epoch: [5][15000/19177] Elapsed 25m 34s (remain 7m 7s) Loss: 0.2126(0.1514) Grad: 27.6481  LR: 0.00000006  \n",
      "Epoch: [5][15500/19177] Elapsed 26m 24s (remain 6m 15s) Loss: 0.2027(0.1513) Grad: 8.6713  LR: 0.00000004  \n",
      "Epoch: [5][16000/19177] Elapsed 27m 14s (remain 5m 24s) Loss: 0.0966(0.1511) Grad: 14.1914  LR: 0.00000003  \n",
      "Epoch: [5][16500/19177] Elapsed 28m 6s (remain 4m 33s) Loss: 0.0540(0.1510) Grad: 17.4531  LR: 0.00000002  \n",
      "Epoch: [5][17000/19177] Elapsed 28m 57s (remain 3m 42s) Loss: 0.0313(0.1511) Grad: 4.9483  LR: 0.00000002  \n",
      "Epoch: [5][17500/19177] Elapsed 29m 49s (remain 2m 51s) Loss: 0.0849(0.1512) Grad: 7.9580  LR: 0.00000001  \n",
      "Epoch: [5][18000/19177] Elapsed 30m 39s (remain 2m 0s) Loss: 0.0725(0.1509) Grad: 6.4907  LR: 0.00000000  \n",
      "Epoch: [5][18500/19177] Elapsed 31m 31s (remain 1m 9s) Loss: 0.1625(0.1509) Grad: 10.2590  LR: 0.00000000  \n",
      "Epoch: [5][19000/19177] Elapsed 32m 23s (remain 0m 18s) Loss: 0.1155(0.1509) Grad: 12.8188  LR: 0.00000000  \n",
      "Epoch: [5][19176/19177] Elapsed 32m 42s (remain 0m 0s) Loss: 0.0834(0.1508) Grad: 7.8147  LR: 0.00000000  \n",
      "EVAL: [0/1590] Elapsed 0m 0s (remain 5m 55s) Loss: 0.2768(0.2768) \n",
      "EVAL: [500/1590] Elapsed 0m 7s (remain 0m 16s) Loss: 0.4694(0.4098) \n",
      "EVAL: [1000/1590] Elapsed 0m 15s (remain 0m 8s) Loss: 0.0401(0.4141) \n",
      "EVAL: [1500/1590] Elapsed 0m 22s (remain 0m 1s) Loss: 0.4745(0.4069) \n",
      "EVAL: [1589/1590] Elapsed 0m 24s (remain 0m 0s) Loss: 0.3180(0.4078) \n",
      "Epoch 5 - avg_train_loss: 0.1508  avg_val_loss: 0.4078  time: 2011s\n",
      "Epoch 5 - Score: 0.4023 - Threshold: 0.02400\n",
      "Our CV score is 0.4048 using a threshold of 0.041\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate one fold\n",
    "train_and_evaluate_one_fold(train, correlations, 0, CFG, add_topic_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f858de-30f7-455a-856f-d9b1631f087f",
   "metadata": {},
   "source": [
    "# Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "435a8cd3-0dc7-453c-b37e-e94d125fc681",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.5.13)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (1.26.11)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (2022.9.24)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->kaggle) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"pip install kaggle\")\n",
    "os.system(\"mkdir -p ~/.kaggle/\")\n",
    "os.system(\"cp /notebooks/kaggle_lecr/kaggle.json ~/.kaggle/\")\n",
    "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "510a516b-6edc-4aac-88c5-93f58b6ece6c",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset name:ex11-trn-all-MiniLM-L12-v2-mnrloss-ep5, output_dir:/notebooks/kaggle_lecr/output/ex11-trn-all-MiniLM-L12-v2-mnrloss-ep5\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128M/128M [00:02<00:00, 53.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch0.pth (128MB)\n",
      "Starting upload for file score.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [00:00<00:00, 287B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: score.pkl (169B)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128M/128M [00:03<00:00, 44.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch2.pth (128MB)\n",
      "Starting upload for file fold_0_topics_ids.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205k/205k [00:00<00:00, 427kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: fold_0_topics_ids.pkl (205KB)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128M/128M [00:02<00:00, 57.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_best_model.pth (128MB)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128M/128M [00:01<00:00, 67.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch1.pth (128MB)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128M/128M [00:01<00:00, 76.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch4.pth (128MB)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128M/128M [00:02<00:00, 49.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex11-finetuning-all-MiniLM-L12-v2-mnrloss-ep10_fold0_42_epoch3.pth (128MB)\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import json\n",
    "\n",
    "def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "    if \"_\" in dataset_name:\n",
    "        raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'sinchir0/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n",
    "\n",
    "if CFG.upload_data:\n",
    "    print(f\"Create Dataset name:{NOTEBOOK_NAME}, output_dir:{OUTPUT_DIR}\")\n",
    "    dataset_create_new(dataset_name=NOTEBOOK_NAME, upload_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fda75-46ff-44dd-9bac-ec7fb5dc0e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879017b-061f-4d99-9f49-e59ab8b2884c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17548.763501,
   "end_time": "2023-02-11T06:57:21.580304",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-11T02:04:52.816803",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "218592928185498e9d59df2150307773": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a52632c7335f4547b3ac2e5873e80780",
        "IPY_MODEL_2ddfc44c7cdf4e50b90af044edb241e7",
        "IPY_MODEL_52fc9a4bd70c4d5d83cfda3bf9c96398"
       ],
       "layout": "IPY_MODEL_a83b337e4b59457a8ac5de9174f9cf9d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2ddfc44c7cdf4e50b90af044edb241e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c155ce2411e4d16b964ab60e162b45c",
       "max": 615170,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9cc63961d65a4e05bc533f5a7c6301e6",
       "tabbable": null,
       "tooltip": null,
       "value": 615170
      }
     },
     "52fc9a4bd70c4d5d83cfda3bf9c96398": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81d6d3f955d94a10a8a9563343a028a4",
       "placeholder": "​",
       "style": "IPY_MODEL_71acb0f9429c474a93233c1f859e53e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 615170/615170 [01:21&lt;00:00, 3806.35it/s]"
      }
     },
     "71acb0f9429c474a93233c1f859e53e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "81d6d3f955d94a10a8a9563343a028a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c155ce2411e4d16b964ab60e162b45c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cc63961d65a4e05bc533f5a7c6301e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a52632c7335f4547b3ac2e5873e80780": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f62b4326bfaf4b439f5b53f0eef9e80d",
       "placeholder": "​",
       "style": "IPY_MODEL_e26c5dc8f53343b399e78f5d540eaf0d",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "a83b337e4b59457a8ac5de9174f9cf9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e26c5dc8f53343b399e78f5d540eaf0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f62b4326bfaf4b439f5b53f0eef9e80d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
