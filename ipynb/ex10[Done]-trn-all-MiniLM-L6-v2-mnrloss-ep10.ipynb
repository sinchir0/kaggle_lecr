{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2b29e0-150c-47b3-9f56-e0241255ca87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"ex10-trn-all-MiniLM-L6-v2-mnrloss-ep10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd0b75a-2889-48af-b1df-a47cb38584bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OUTPUT_DIR = f\"/notebooks/kaggle_lecr/output/{NOTEBOOK_NAME}\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea3d0df-f4e8-4202-a89b-f5926005aa42",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch==1.12.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.12.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.9/site-packages (from torch==1.12.0) (4.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers==0.12.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.12.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.20.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (4.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (1.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (0.13.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.20.1) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip3 install torch==1.12.0 --extra-index-url https://download.pytorch.org/whl/cu116\")\n",
    "os.system(\"pip install tokenizers==0.12.1\")\n",
    "os.system(\"pip install transformers==4.20.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09c789d-506f-4886-b7ee-c222198479fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 11 12:15:15 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   51C    P8    24W / 230W |      0MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6819dc6-ff40-4f79-8685-02db3c6a8f77",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('pip install python-dotenv')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95534da-f206-4f29-a023-0b49a499bdf9",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.2.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.23.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install scikit-learn==1.2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af13c3b",
   "metadata": {
    "papermill": {
     "duration": 7.561173,
     "end_time": "2023-02-11T02:05:08.553027",
     "exception": false,
     "start_time": "2023-02-11T02:05:00.991854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# Libraries\n",
    "# =========================================================================================\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f108c3d",
   "metadata": {
    "papermill": {
     "duration": 0.01567,
     "end_time": "2023-02-11T02:05:08.574968",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.559298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Configurations\n",
    "# =========================================================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    upload_data = True\n",
    "    wandb = True\n",
    "    print_freq = 500\n",
    "    num_workers = 4\n",
    "    # model = \"xlm-roberta-base\"\n",
    "    model = \"/notebooks/kaggle_lecr/output/ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10\"\n",
    "    gradient_checkpointing = False\n",
    "    num_cycles = 0.5\n",
    "    warmup_ratio = 0.1\n",
    "    encoder_lr = 1e-5\n",
    "    decoder_lr = 1e-4\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    batch_size = 64#32\n",
    "    weight_decay = 0.01\n",
    "    max_grad_norm = 0.012\n",
    "    max_len = 512\n",
    "    n_folds = 5\n",
    "    seed = 42\n",
    "    epochs = 5\n",
    "    data_url = \"/notebooks/kaggle_lecr/data/learning-equality-curriculum-recommendations\"\n",
    "    train_set_url = \"/notebooks/kaggle_lecr/output/ex10-uns-all-MiniLM-L6-v2-mnrloss-ep10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf556033-94aa-4878-9379-1cd79a7bc14d",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb==0.13.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.13.3)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (2.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.16.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (6.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (0.4.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.0.11)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (60.10.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.16.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (8.1.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (5.9.3)\n",
      "Requirement already satisfied: pathtools in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (0.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (2.28.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.3.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (3.1.31)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (3.20.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb==0.13.3) (4.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (2.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.13.3) (5.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinchir0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/kaggle_lecr/ipynb/wandb/run-20230311_121524-ad5lj8ly</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sinchir0/LECR/runs/ad5lj8ly\" target=\"_blank\">ex10-trn-all-MiniLM-L6-v2-mnrloss-ep10</a></strong> to <a href=\"https://wandb.ai/sinchir0/LECR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "if CFG.wandb:\n",
    "    os.system('pip install wandb==0.13.3')\n",
    "    import wandb\n",
    "\n",
    "    try:\n",
    "        # for kaggle\n",
    "        # from kaggle_secrets import UserSecretsClient\n",
    "        # user_secrets = UserSecretsClient()\n",
    "        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "        \n",
    "        # for paperspace\n",
    "        secret_value_0 = os.getenv('WANDB_API_KEY')\n",
    "        wandb.login(key=secret_value_0)\n",
    "        \n",
    "        anony = None\n",
    "    except:\n",
    "        anony = \"must\"\n",
    "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "\n",
    "    def class2dict(f):\n",
    "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "    run = wandb.init(project='LECR',\n",
    "                     entity=\"sinchir0\",\n",
    "                     name=NOTEBOOK_NAME,\n",
    "                     config=class2dict(CFG),\n",
    "                     group=\"trn\",\n",
    "                     job_type=\"train\",\n",
    "                     anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea8f99c",
   "metadata": {
    "papermill": {
     "duration": 0.014544,
     "end_time": "2023-02-11T02:05:08.595307",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.580763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Seed everything for deterministic results\n",
    "# =========================================================================================\n",
    "def seed_everything(cfg):\n",
    "    random.seed(cfg.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    torch.cuda.manual_seed(cfg.seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd14795",
   "metadata": {
    "papermill": {
     "duration": 0.015773,
     "end_time": "2023-02-11T02:05:08.616987",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.601214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Data Loading\n",
    "# =========================================================================================\n",
    "def read_data(cfg):\n",
    "    # train = pd.read_csv(f\"{cfg.train_set_url}/train.csv\")\n",
    "    train = pd.read_pickle(f\"{cfg.train_set_url}/train.pkl\")\n",
    "    \n",
    "    topics = pd.read_csv(cfg.data_url + \"/\" + \"topics.csv\")\n",
    "    content = pd.read_csv(cfg.data_url + \"/\" + \"content.csv\")\n",
    "    correlations = pd.read_csv(cfg.data_url + \"/\" + \"correlations.csv\")\n",
    "\n",
    "    topics[\"title\"] = topics[\"title\"].fillna(\"\")\n",
    "    content[\"title\"] = content[\"title\"].fillna(\"\")\n",
    "    \n",
    "    topics[\"description\"] = topics[\"description\"].fillna(\"\")\n",
    "    content[\"description\"] = content[\"description\"].fillna(\"\")\n",
    "    \n",
    "    content['text'] = content['text'].fillna(\"\")\n",
    "    \n",
    "    print(' ')\n",
    "    print('-' * 50)\n",
    "    print(f\"train.shape: {train.shape}\")\n",
    "    print(f\"correlations.shape: {correlations.shape}\")\n",
    "    return train, topics, content, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c94a6b",
   "metadata": {
    "papermill": {
     "duration": 0.013152,
     "end_time": "2023-02-11T02:05:08.635842",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.622690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(train: pd.DataFrame):\n",
    "    # Create feature column\n",
    "    # train['text'] = train['topics_titles'] + '[SEP]' + train['content_titles']\n",
    "    train['text'] = train['topics_texts'] + '[SEP]' + train['content_texts']\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d457e372",
   "metadata": {
    "papermill": {
     "duration": 0.017013,
     "end_time": "2023-02-11T02:05:08.658444",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.641431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_cat_info(train: pd.DataFrame, topics: pd.DataFrame, content:pd.DataFrame):\n",
    "    merge_train = pd.merge(train, topics[[\"id\", \"level\", \"category\"]], left_on=\"topics_ids\", right_on=\"id\", how=\"left\")\n",
    "    merge_train = merge_train.drop(\"id\", axis=1)\n",
    "    merge_train = pd.merge(merge_train, content[[\"id\", \"kind\"]], left_on=\"content_ids\", right_on=\"id\", how=\"left\")\n",
    "    merge_train = merge_train.drop(\"id\", axis=1)\n",
    "    \n",
    "    merge_train[\"level_tag\"] = merge_train[\"level\"].apply(lambda x: f\"[LEVEL{x}]\")\n",
    "    merge_train[\"category_tag\"] = merge_train[\"category\"].apply(lambda x: f\"[CATEGORY_{x.upper()}]\")\n",
    "    merge_train[\"kind_tag\"] = merge_train[\"kind\"].apply(lambda x: f\"[KIND_{x.upper()}]\")\n",
    "    \n",
    "    level_tag_list = sorted(merge_train[\"level_tag\"].unique()) \n",
    "    category_list = sorted(merge_train[\"category_tag\"].unique()) \n",
    "    kind_list = sorted(merge_train[\"kind_tag\"].unique()) \n",
    "    \n",
    "    # train['topics_titles'] = merge_train['level_tag'] + merge_train[\"category_tag\"] + merge_train['topics_titles'] \n",
    "    train['topics_texts'] = merge_train['level_tag'] + merge_train[\"category_tag\"] + merge_train['topics_texts'] \n",
    "    # train['content_titles'] = merge_train['kind_tag'] + merge_train['content_titles']\n",
    "    train['content_texts'] = merge_train['kind_tag'] + merge_train['content_texts']\n",
    "    \n",
    "    return train, level_tag_list, category_list, kind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a68033ec",
   "metadata": {
    "papermill": {
     "duration": 0.01453,
     "end_time": "2023-02-11T02:05:08.678562",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.664032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# CV split\n",
    "# =========================================================================================\n",
    "def cv_split(train, cfg):\n",
    "    kfold = StratifiedGroupKFold(n_splits = cfg.n_folds, shuffle = True, random_state = cfg.seed)\n",
    "    for num, (train_index, val_index) in enumerate(kfold.split(train, train['target'], train['topics_ids'])):\n",
    "        train.loc[val_index, 'fold'] = int(num)\n",
    "    train['fold'] = train['fold'].astype(int)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7007386",
   "metadata": {
    "papermill": {
     "duration": 0.016546,
     "end_time": "2023-02-11T02:05:08.702048",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.685502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# F2 score metric\n",
    "# =========================================================================================\n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f2 = tp / (tp + 0.2 * fp + 0.8 * fn)\n",
    "    return round(f2.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79f24de",
   "metadata": {
    "papermill": {
     "duration": 0.015781,
     "end_time": "2023-02-11T02:05:08.723530",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.707749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Get max length\n",
    "# =========================================================================================\n",
    "def get_max_length(train, cfg):\n",
    "    lengths = []\n",
    "    for text in tqdm(train['text'].fillna(\"\").values, total = len(train)):\n",
    "        length = len(cfg.tokenizer(text, add_special_tokens = False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "    cfg.max_len = min(max(lengths) + 5, cfg.max_len) # cls + sep + level + category + kind\n",
    "    print(f\"max_len: {cfg.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8d29cf",
   "metadata": {
    "papermill": {
     "duration": 0.058232,
     "end_time": "2023-02-11T02:05:08.787596",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.729364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Prepare input, tokenize\n",
    "# =========================================================================================\n",
    "def prepare_input(text, cfg):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "        max_length = cfg.max_len,\n",
    "        pad_to_max_length = True,\n",
    "        truncation = True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Custom dataset\n",
    "# =========================================================================================\n",
    "class custom_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "        self.labels = df['target'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item], self.cfg)\n",
    "        label = torch.tensor(self.labels[item], dtype = torch.float)\n",
    "        return inputs, label\n",
    "    \n",
    "# =========================================================================================\n",
    "# Collate function for training\n",
    "# =========================================================================================\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Mean pooling class\n",
    "# =========================================================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "# =========================================================================================\n",
    "# Model\n",
    "# =========================================================================================\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states = True)\n",
    "        self.config.hidden_dropout = 0.0\n",
    "        self.config.hidden_dropout_prob = 0.0\n",
    "        self.config.attention_dropout = 0.0\n",
    "        self.config.attention_probs_dropout_prob = 0.0\n",
    "        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n",
    "        # AutoTokenizer.from_pretrainedでadditional_special_tokensをした際は、増えたtoken分、新しい語彙として登録が必要らしい\n",
    "        # https://cocoinit23.com/pytorch-runtimeerror-cuda-error-device-side-assert-triggered/\n",
    "        self.model.resize_token_embeddings(len(cfg.tokenizer))\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "    \n",
    "# =========================================================================================\n",
    "# Helper functions\n",
    "# =========================================================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "# =========================================================================================\n",
    "# Train function loop\n",
    "# =========================================================================================\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled = True)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, target) in enumerate(train_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled = True):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch + 1, \n",
    "                          step, \n",
    "                          len(train_loader), \n",
    "                          remain = timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                          loss = losses,\n",
    "                          grad_norm = grad_norm,\n",
    "                          lr = scheduler.get_lr()[0]))\n",
    "    return losses.avg\n",
    "\n",
    "# =========================================================================================\n",
    "# Valid function loop\n",
    "# =========================================================================================\n",
    "def valid_fn(valid_loader, model, criterion, device, cfg):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, target) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().squeeze().to('cpu').numpy().reshape(-1))\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, \n",
    "                          len(valid_loader),\n",
    "                          loss = losses,\n",
    "                          remain = timeSince(start, float(step + 1) / len(valid_loader))))\n",
    "    predictions = np.concatenate(preds, axis = 0)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "# =========================================================================================\n",
    "# Get best threshold\n",
    "# =========================================================================================\n",
    "def get_best_threshold(x_val, val_predictions, correlations):\n",
    "    best_score = 0\n",
    "    best_threshold = None\n",
    "    for thres in np.arange(0.001, 0.1, 0.001):\n",
    "        x_val['predictions'] = np.where(val_predictions > thres, 1, 0)\n",
    "        x_val1 = x_val[x_val['predictions'] == 1]\n",
    "        x_val1 = x_val1.groupby(['topics_ids'])['content_ids'].unique().reset_index()\n",
    "        x_val1['content_ids'] = x_val1['content_ids'].apply(lambda x: ' '.join(x))\n",
    "        x_val1.columns = ['topic_id', 'predictions']\n",
    "        x_val0 = pd.Series(x_val['topics_ids'].unique())\n",
    "        x_val0 = x_val0[~x_val0.isin(x_val1['topic_id'])]\n",
    "        x_val0 = pd.DataFrame({'topic_id': x_val0.values, 'predictions': \"\"})\n",
    "        x_val_r = pd.concat([x_val1, x_val0], axis = 0, ignore_index = True)\n",
    "        x_val_r = x_val_r.merge(correlations, how = 'left', on = 'topic_id')\n",
    "        score = f2_score(x_val_r['content_ids'], x_val_r['predictions'])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = thres\n",
    "    return best_score, best_threshold\n",
    "    \n",
    "# =========================================================================================\n",
    "# Train & Evaluate\n",
    "# =========================================================================================\n",
    "def train_and_evaluate_one_fold(train, correlations, fold, cfg, add_topic_content: list):\n",
    "    # 高速化、計算の再現性は担保されない、https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    print(' ')\n",
    "    print(f\"========== fold: {fold} training ==========\")\n",
    "    # Split train & validation\n",
    "    x_train = train[train['fold'] != fold]\n",
    "    x_val = train[train['fold'] == fold]\n",
    "    \n",
    "    # categoryがsourceのtopicは評価に使わない\n",
    "    x_val = x_val[~x_val[\"topics_texts\"].str.contains(\"CATEGORY_SOURCE\")]\n",
    "    \n",
    "    # 追加したpositiveのtopic, contentは評価には使わない\n",
    "    x_val = x_val[~(x_val[\"topics_ids\"] + x_val[\"content_ids\"]).isin(add_topic_content)]\n",
    "    \n",
    "    valid_labels = x_val['target'].values\n",
    "    train_dataset = custom_dataset(x_train, cfg)\n",
    "    valid_dataset = custom_dataset(x_val, cfg)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = True, \n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "    # Get model\n",
    "    model = custom_model(cfg)\n",
    "    model.to(device)\n",
    "    # Optimizer\n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay = 0.0):\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "            'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "    optimizer_parameters = get_optimizer_params(\n",
    "        model, \n",
    "        encoder_lr = cfg.encoder_lr, \n",
    "        decoder_lr = cfg.decoder_lr,\n",
    "        weight_decay = cfg.weight_decay\n",
    "    )\n",
    "    optimizer = AdamW(\n",
    "        optimizer_parameters, \n",
    "        lr = cfg.encoder_lr, \n",
    "        eps = cfg.eps, \n",
    "        betas = cfg.betas\n",
    "    )\n",
    "    num_train_steps = int(len(x_train) / cfg.batch_size * cfg.epochs)\n",
    "    num_warmup_steps = num_train_steps * cfg.warmup_ratio\n",
    "    # Scheduler\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps = num_warmup_steps, \n",
    "        num_training_steps = num_train_steps, \n",
    "        num_cycles = cfg.num_cycles\n",
    "        )\n",
    "    # Training & Validation loop\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "    best_score = 0\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        start_time = time.time()\n",
    "        # Train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg)\n",
    "        # Validation\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device, cfg)\n",
    "        # Compute f2_score\n",
    "        score, threshold = get_best_threshold(x_val, predictions, correlations)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        print(f'Epoch {epoch+1} - Score: {score:.4f} - Threshold: {threshold:.5f}')\n",
    "        torch.save(\n",
    "            {'model': model.state_dict(), 'predictions': predictions}, \n",
    "            f\"{OUTPUT_DIR}/{cfg.model.replace('/', '-')}_fold{fold}_{cfg.seed}_epoch{epoch}.pth\"\n",
    "        )\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save(\n",
    "                {'model': model.state_dict(), 'predictions': predictions}, \n",
    "                f\"{OUTPUT_DIR}/{cfg.model.replace('/', '-')}_fold{fold}_{cfg.seed}_best_model.pth\"\n",
    "                )\n",
    "            val_predictions = predictions\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    # Get best threshold\n",
    "    best_score, best_threshold = get_best_threshold(x_val, val_predictions, correlations)\n",
    "    # Save Score, Threshold\n",
    "    score = {\"best_score\": best_score, \"best_threshold\": best_threshold}\n",
    "    with open(f\"{OUTPUT_DIR}/score.pkl\", \"wb\") as f:\n",
    "        pickle.dump(score, f)\n",
    "    print(f'Our CV score is {best_score} using a threshold of {best_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3f57c04",
   "metadata": {
    "papermill": {
     "duration": 0.019865,
     "end_time": "2023-02-11T02:05:08.813594",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.793729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed everything\n",
    "seed_everything(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75b78f49",
   "metadata": {
    "papermill": {
     "duration": 22.091749,
     "end_time": "2023-02-11T02:05:30.911554",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.819805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "train.shape: (615170, 5)\n",
      "correlations.shape: (61517, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train, topics, content, correlations = read_data(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a72c73ae-6a03-4db9-8f7f-eba633295b17",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics_ids       0\n",
       "content_ids      0\n",
       "topics_texts     0\n",
       "content_texts    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a406b66-a473-43c5-937f-95b15c667142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d2dbd4e4884a289743584055eb2b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_parent_text(topics: pd.DataFrame):\n",
    "    topics = topics.fillna('')\n",
    "    id_full_text = {}\n",
    "    id_to_text = {}\n",
    "    for i, row in topics.iterrows():\n",
    "        id_to_text[row.id] = [row.title, row.parent]\n",
    "    print('done')\n",
    "    def get_full_text(id):\n",
    "        if id in id_full_text:\n",
    "            return id_full_text[id]\n",
    "        data = id_to_text[id]\n",
    "        # full_text = f'{data[0]} < {get_full_text(data[1])}' if data[1] != '' else data[0]\n",
    "        full_text = f'{data[0]} > {get_full_text(data[1])}' if data[1] != '' else data[0]\n",
    "        id_full_text[id] = full_text\n",
    "        return full_text\n",
    "    tqdm.pandas()\n",
    "    topics['title'] = topics.id.progress_apply(get_full_text)\n",
    "    # Sort by title length to make inference faster\n",
    "    topics['length'] = topics['title'].apply(lambda x: len(x))\n",
    "    topics.sort_values('length', inplace = True)\n",
    "    del id_full_text\n",
    "    del id_to_text\n",
    "    return topics\n",
    "\n",
    "# add parent text\n",
    "topics = add_parent_text(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0e6c17a-1e04-43e3-8522-645a7e50d555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# positive sampleを足す\n",
    "def add_positive_sample(train: pd.DataFrame, correlations: pd.DataFrame, topics: pd.DataFrame, content: pd.DataFrame):\n",
    "    \n",
    "    topic_text_dict = dict(zip(topics[\"id\"], topics['title'] + \" \" + topics['description']))\n",
    "    content_text_dict = dict(zip(content[\"id\"], content['title'] + \" \" + content['description']))\n",
    "    \n",
    "    correlations[\"content_ids_list\"] = correlations[\"content_ids\"].apply(lambda x : x.split())\n",
    "    \n",
    "    all_positive_sample = correlations.explode(\"content_ids_list\")[[\"topic_id\",\"content_ids_list\"]]\n",
    "    all_positive_sample = all_positive_sample.rename(columns={\"topic_id\":\"topics_ids\",\"content_ids_list\":\"content_ids\"})\n",
    "    \n",
    "    all_positive_sample[\"topics_texts\"] = all_positive_sample[\"topics_ids\"].map(topic_text_dict)\n",
    "    all_positive_sample[\"content_texts\"] = all_positive_sample[\"content_ids\"].map(content_text_dict)\n",
    "    all_positive_sample[\"target\"] = 1\n",
    "    \n",
    "    all_positive_sample = all_positive_sample.reset_index(drop=True)\n",
    "    \n",
    "    # 追加するtopic, contentのみを持つlistを生成\n",
    "    all_positive_topic_content = (all_positive_sample[\"topics_ids\"] + all_positive_sample[\"content_ids\"]).tolist()\n",
    "    train_positive = train[train[\"target\"] == 1]\n",
    "    train_positive_topic_content = (train_positive[\"topics_ids\"] + train_positive[\"content_ids\"]).tolist()\n",
    "    add_topic_content = list(set(all_positive_topic_content) - set(train_positive_topic_content))\n",
    "    \n",
    "    # trainにpositive sampleを追加\n",
    "    train = pd.concat([train, all_positive_sample]).drop_duplicates(subset=[\"topics_ids\",\"content_ids\"], keep='first')\n",
    "    train = train.sort_values(\"topics_ids\")\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    return train, add_topic_content\n",
    "\n",
    "train, add_topic_content = add_positive_sample(train, correlations, topics, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67fa349b-7b57-43d6-844e-533dbbeced8a",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"topics_texts\"] = train[\"topics_texts\"].apply(lambda x : \" \".join(x.split()[:128]))\n",
    "train[\"content_texts\"] = train[\"content_texts\"].apply(lambda x : \" \".join(x.split()[:128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cacb8ef-7b40-44a8-9923-e811d089ff1c",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160859"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(add_topic_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27837264",
   "metadata": {
    "papermill": {
     "duration": 0.02252,
     "end_time": "2023-02-11T02:05:30.947474",
     "exception": false,
     "start_time": "2023-02-11T02:05:30.924954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train[:1000]\n",
    "    CFG.epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4205a7c0",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.095627,
     "end_time": "2023-02-11T02:05:33.051735",
     "exception": false,
     "start_time": "2023-02-11T02:05:30.956108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, level_tag_list, category_list, kind_list = merge_cat_info(train, topics, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb705e19",
   "metadata": {
    "papermill": {
     "duration": 0.227458,
     "end_time": "2023-02-11T02:05:33.352932",
     "exception": false,
     "start_time": "2023-02-11T02:05:33.125474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69ad3a19-92b1-4794-9bd7-6daee885cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks/kaggle_lecr/output/ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09133fac",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.251238,
     "end_time": "2023-02-11T02:05:41.664455",
     "exception": false,
     "start_time": "2023-02-11T02:05:33.413217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "CFG.tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model,\n",
    "    additional_special_tokens = level_tag_list + category_list + kind_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc3017c7",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018461,
     "end_time": "2023-02-11T02:05:41.691787",
     "exception": false,
     "start_time": "2023-02-11T02:05:41.673326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[LEVEL0]',\n",
       " '[LEVEL10]',\n",
       " '[LEVEL1]',\n",
       " '[LEVEL2]',\n",
       " '[LEVEL3]',\n",
       " '[LEVEL4]',\n",
       " '[LEVEL5]',\n",
       " '[LEVEL6]',\n",
       " '[LEVEL7]',\n",
       " '[LEVEL8]',\n",
       " '[LEVEL9]',\n",
       " '[CATEGORY_ALIGNED]',\n",
       " '[CATEGORY_SOURCE]',\n",
       " '[CATEGORY_SUPPLEMENTAL]',\n",
       " '[KIND_AUDIO]',\n",
       " '[KIND_DOCUMENT]',\n",
       " '[KIND_EXERCISE]',\n",
       " '[KIND_HTML5]',\n",
       " '[KIND_VIDEO]']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.tokenizer.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b490a510-9e68-4203-b3a1-9bd5ce3c787a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# categoryがsourceのnegativeデータを減らし、計算時間を短くする\n",
    "# train[\"is_category_source\"] = train[\"topics_texts\"].str.contains(\"CATEGORY_SOURCE\")\n",
    "# train = train[~(train[\"is_category_source\"] & (train[\"target\"] == 0))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4871bf1d-8673-4cec-8472-7daa58e3e865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 計算を終わらせるため、行を減らす\n",
    "# if not CFG.debug:\n",
    "#     train = train.sample(200000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e5a3ce5",
   "metadata": {
    "papermill": {
     "duration": 24.616901,
     "end_time": "2023-02-11T02:06:06.316153",
     "exception": false,
     "start_time": "2023-02-11T02:05:41.699252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CV split\n",
    "train = cv_split(train, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "234ea5e9-9f5c-4e84-a884-de3ab5d0cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = train[[\"topics_ids\",\"fold\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be63cf4e-0915-42ed-b32b-9adf32adb3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.drop_duplicates().to_csv(\"topics_ids_fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb66dca3-cbb8-4d3e-a012-eb589fc18c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_list = train[train[\"fold\"] == 0][\"topics_ids\"].unique().tolist()\n",
    "with open(f\"{OUTPUT_DIR}/fold_0_topics_ids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fold0_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "287e8991-6d5a-470d-9459-2cc95718db13",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    156476\n",
      "1    155517\n",
      "2    155165\n",
      "4    154503\n",
      "0    154368\n",
      "Name: fold, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"fold\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "494577d4-2513-465c-938c-c4d635829e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84d901da-9881-4008-8a1d-53655a9722ec",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    496110\n",
       "1    279919\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07e9b843",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 81.097871,
     "end_time": "2023-02-11T02:07:27.589260",
     "exception": false,
     "start_time": "2023-02-11T02:06:06.491389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d209546837a3452ca475e77ec6acb1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/776029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len: 512\n"
     ]
    }
   ],
   "source": [
    "# Get max length\n",
    "get_max_length(train, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "896807cf-cf68-42f9-aca1-118b255065e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5253160",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 17391.060041,
     "end_time": "2023-02-11T06:57:18.656824",
     "exception": false,
     "start_time": "2023-02-11T02:07:27.596783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "========== fold: 0 training ==========\n",
      "Epoch: [1][0/9713] Elapsed 0m 1s (remain 235m 48s) Loss: 0.6917(0.6917) Grad: 0.7500  LR: 0.00000000  \n",
      "Epoch: [1][500/9713] Elapsed 1m 2s (remain 19m 1s) Loss: 0.6261(0.6705) Grad: 0.6528  LR: 0.00000103  \n",
      "Epoch: [1][1000/9713] Elapsed 2m 1s (remain 17m 40s) Loss: 0.7138(0.6432) Grad: 1.9751  LR: 0.00000206  \n",
      "Epoch: [1][1500/9713] Elapsed 3m 1s (remain 16m 30s) Loss: 0.5211(0.6075) Grad: 2.8637  LR: 0.00000309  \n",
      "Epoch: [1][2000/9713] Elapsed 4m 0s (remain 15m 25s) Loss: 0.5156(0.5741) Grad: 5.0273  LR: 0.00000412  \n",
      "Epoch: [1][2500/9713] Elapsed 4m 59s (remain 14m 25s) Loss: 0.4777(0.5509) Grad: 3.4151  LR: 0.00000515  \n",
      "Epoch: [1][3000/9713] Elapsed 6m 0s (remain 13m 27s) Loss: 0.4133(0.5332) Grad: 4.1347  LR: 0.00000618  \n",
      "Epoch: [1][3500/9713] Elapsed 7m 2s (remain 12m 29s) Loss: 0.5144(0.5189) Grad: 5.2904  LR: 0.00000721  \n",
      "Epoch: [1][4000/9713] Elapsed 8m 3s (remain 11m 30s) Loss: 0.4193(0.5083) Grad: 6.8934  LR: 0.00000824  \n",
      "Epoch: [1][4500/9713] Elapsed 9m 3s (remain 10m 29s) Loss: 0.4429(0.4983) Grad: 3.5791  LR: 0.00000927  \n",
      "Epoch: [1][5000/9713] Elapsed 10m 5s (remain 9m 30s) Loss: 0.4157(0.4898) Grad: 5.1088  LR: 0.00001000  \n",
      "Epoch: [1][5500/9713] Elapsed 11m 5s (remain 8m 29s) Loss: 0.3857(0.4820) Grad: 5.6759  LR: 0.00000999  \n",
      "Epoch: [1][6000/9713] Elapsed 12m 5s (remain 7m 28s) Loss: 0.4353(0.4743) Grad: 8.5474  LR: 0.00000998  \n",
      "Epoch: [3][8000/9713] Elapsed 16m 1s (remain 3m 25s) Loss: 0.2816(0.2694) Grad: 6.9977  LR: 0.00000474  \n",
      "Epoch: [3][8500/9713] Elapsed 17m 2s (remain 2m 25s) Loss: 0.3237(0.2688) Grad: 8.1445  LR: 0.00000456  \n",
      "Epoch: [3][9000/9713] Elapsed 18m 1s (remain 1m 25s) Loss: 0.2706(0.2681) Grad: 7.6679  LR: 0.00000439  \n",
      "Epoch: [3][9500/9713] Elapsed 19m 2s (remain 0m 25s) Loss: 0.1684(0.2678) Grad: 5.3585  LR: 0.00000421  \n",
      "Epoch: [3][9712/9713] Elapsed 19m 29s (remain 0m 0s) Loss: 0.2404(0.2677) Grad: 7.5883  LR: 0.00000413  \n",
      "EVAL: [0/787] Elapsed 0m 0s (remain 3m 43s) Loss: 0.3258(0.3258) \n",
      "EVAL: [500/787] Elapsed 0m 10s (remain 0m 6s) Loss: 0.5540(0.3468) \n",
      "EVAL: [786/787] Elapsed 0m 16s (remain 0m 0s) Loss: 0.4758(0.3516) \n",
      "Epoch 3 - avg_train_loss: 0.2677  avg_val_loss: 0.3516  time: 1212s\n",
      "Epoch 3 - Score: 0.3601 - Threshold: 0.09700\n",
      "Epoch 3 - Save Best Score: 0.3601 Model\n",
      "Epoch: [4][0/9713] Elapsed 0m 0s (remain 90m 28s) Loss: 0.1864(0.1864) Grad: 5.1129  LR: 0.00000413  \n",
      "Epoch: [4][500/9713] Elapsed 0m 58s (remain 18m 4s) Loss: 0.2402(0.2426) Grad: 7.6734  LR: 0.00000396  \n",
      "Epoch: [4][1000/9713] Elapsed 1m 57s (remain 17m 1s) Loss: 0.2366(0.2421) Grad: 6.3725  LR: 0.00000378  \n",
      "Epoch: [4][1500/9713] Elapsed 2m 56s (remain 16m 8s) Loss: 0.1803(0.2434) Grad: 5.7810  LR: 0.00000361  \n",
      "Epoch: [4][2000/9713] Elapsed 3m 57s (remain 15m 14s) Loss: 0.1651(0.2432) Grad: 5.5528  LR: 0.00000344  \n",
      "Epoch: [4][2500/9713] Elapsed 4m 56s (remain 14m 13s) Loss: 0.1967(0.2423) Grad: 8.3581  LR: 0.00000327  \n",
      "Epoch: [4][3000/9713] Elapsed 5m 56s (remain 13m 16s) Loss: 0.2178(0.2419) Grad: 7.7150  LR: 0.00000310  \n",
      "Epoch: [5][3500/9713] Elapsed 6m 57s (remain 12m 21s) Loss: 0.1760(0.2241) Grad: 7.2613  LR: 0.00000049  \n",
      "Epoch: [5][4000/9713] Elapsed 7m 59s (remain 11m 24s) Loss: 0.2729(0.2236) Grad: 8.5085  LR: 0.00000042  \n",
      "Epoch: [5][4500/9713] Elapsed 8m 58s (remain 10m 23s) Loss: 0.1788(0.2239) Grad: 8.8768  LR: 0.00000035  \n",
      "Epoch: [5][5000/9713] Elapsed 9m 58s (remain 9m 24s) Loss: 0.3213(0.2238) Grad: 10.8255  LR: 0.00000028  \n",
      "Epoch: [5][5500/9713] Elapsed 11m 0s (remain 8m 25s) Loss: 0.2404(0.2243) Grad: 8.2793  LR: 0.00000023  \n",
      "Epoch: [5][6000/9713] Elapsed 12m 0s (remain 7m 25s) Loss: 0.4546(0.2241) Grad: 11.9473  LR: 0.00000018  \n",
      "Epoch: [5][6500/9713] Elapsed 13m 1s (remain 6m 26s) Loss: 0.1707(0.2242) Grad: 9.0656  LR: 0.00000013  \n",
      "Epoch: [5][7000/9713] Elapsed 14m 1s (remain 5m 26s) Loss: 0.1829(0.2239) Grad: 6.8294  LR: 0.00000009  \n",
      "Epoch: [5][7500/9713] Elapsed 15m 1s (remain 4m 25s) Loss: 0.1217(0.2232) Grad: 4.6262  LR: 0.00000006  \n",
      "Epoch: [5][8000/9713] Elapsed 16m 0s (remain 3m 25s) Loss: 0.2159(0.2233) Grad: 9.0677  LR: 0.00000004  \n",
      "Epoch: [5][8500/9713] Elapsed 17m 0s (remain 2m 25s) Loss: 0.1221(0.2233) Grad: 5.3619  LR: 0.00000002  \n",
      "Epoch: [5][9000/9713] Elapsed 18m 0s (remain 1m 25s) Loss: 0.1602(0.2234) Grad: 6.0630  LR: 0.00000001  \n",
      "Epoch: [5][9500/9713] Elapsed 18m 59s (remain 0m 25s) Loss: 0.3127(0.2234) Grad: 9.4497  LR: 0.00000000  \n",
      "Epoch: [5][9712/9713] Elapsed 19m 24s (remain 0m 0s) Loss: 0.1443(0.2234) Grad: 5.7432  LR: 0.00000000  \n",
      "EVAL: [0/787] Elapsed 0m 0s (remain 3m 45s) Loss: 0.3288(0.3288) \n",
      "EVAL: [500/787] Elapsed 0m 10s (remain 0m 5s) Loss: 0.4817(0.3280) \n",
      "EVAL: [786/787] Elapsed 0m 16s (remain 0m 0s) Loss: 0.3709(0.3311) \n",
      "Epoch 5 - avg_train_loss: 0.2234  avg_val_loss: 0.3311  time: 1206s\n",
      "Epoch 5 - Score: 0.3690 - Threshold: 0.06800\n",
      "Epoch 5 - Save Best Score: 0.3690 Model\n",
      "Our CV score is 0.369 using a threshold of 0.068\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate one fold\n",
    "train_and_evaluate_one_fold(train, correlations, 0, CFG, add_topic_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f858de-30f7-455a-856f-d9b1631f087f",
   "metadata": {},
   "source": [
    "# Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "435a8cd3-0dc7-453c-b37e-e94d125fc681",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.13.tar.gz (63 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.3/63.3 kB 16.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (2022.9.24)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (4.64.1)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (1.26.11)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.2/78.2 kB 28.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->kaggle) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->kaggle) (3.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.13-py3-none-any.whl size=77733 sha256=be3685cdcd1e33906147ca2e1923f368854c2923ea56a61bb03dc49c9a3c030d\n",
      "  Stored in directory: /root/.cache/pip/wheels/92/8c/37/96a1971bedc1e74057af1e4852f18de7e8286dea4f12928e6c\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.13 python-slugify-8.0.1 text-unidecode-1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"pip install kaggle\")\n",
    "os.system(\"mkdir -p ~/.kaggle/\")\n",
    "os.system(\"cp /notebooks/kaggle_lecr/kaggle.json ~/.kaggle/\")\n",
    "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "510a516b-6edc-4aac-88c5-93f58b6ece6c",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset name:ex10-trn-all-MiniLM-L6-v2-mnrloss-ep10, output_dir:/notebooks/kaggle_lecr/output/ex10-trn-all-MiniLM-L6-v2-mnrloss-ep10\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87.0M/87.0M [00:01<00:00, 55.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch1.pth (87MB)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87.0M/87.0M [00:01<00:00, 55.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_best_model.pth (87MB)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87.0M/87.0M [00:01<00:00, 55.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch2.pth (87MB)\n",
      "Starting upload for file score.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [00:00<00:00, 293B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: score.pkl (169B)\n",
      "Starting upload for file fold_0_topics_ids.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204k/204k [00:00<00:00, 432kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: fold_0_topics_ids.pkl (204KB)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87.0M/87.0M [00:02<00:00, 39.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch4.pth (87MB)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87.0M/87.0M [00:01<00:00, 52.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch3.pth (87MB)\n",
      "Starting upload for file -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87.0M/87.0M [00:01<00:00, 58.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: -notebooks-kaggle_lecr-output-ex10-finetuning-all-MiniLM-L6-v2-mnrloss-ep10_fold0_42_epoch0.pth (87MB)\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import json\n",
    "\n",
    "def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "    if \"_\" in dataset_name:\n",
    "        raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'sinchir0/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n",
    "\n",
    "if CFG.upload_data:\n",
    "    print(f\"Create Dataset name:{NOTEBOOK_NAME}, output_dir:{OUTPUT_DIR}\")\n",
    "    dataset_create_new(dataset_name=NOTEBOOK_NAME, upload_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fda75-46ff-44dd-9bac-ec7fb5dc0e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879017b-061f-4d99-9f49-e59ab8b2884c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17548.763501,
   "end_time": "2023-02-11T06:57:21.580304",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-11T02:04:52.816803",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "218592928185498e9d59df2150307773": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a52632c7335f4547b3ac2e5873e80780",
        "IPY_MODEL_2ddfc44c7cdf4e50b90af044edb241e7",
        "IPY_MODEL_52fc9a4bd70c4d5d83cfda3bf9c96398"
       ],
       "layout": "IPY_MODEL_a83b337e4b59457a8ac5de9174f9cf9d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2ddfc44c7cdf4e50b90af044edb241e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c155ce2411e4d16b964ab60e162b45c",
       "max": 615170,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9cc63961d65a4e05bc533f5a7c6301e6",
       "tabbable": null,
       "tooltip": null,
       "value": 615170
      }
     },
     "52fc9a4bd70c4d5d83cfda3bf9c96398": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81d6d3f955d94a10a8a9563343a028a4",
       "placeholder": "​",
       "style": "IPY_MODEL_71acb0f9429c474a93233c1f859e53e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 615170/615170 [01:21&lt;00:00, 3806.35it/s]"
      }
     },
     "71acb0f9429c474a93233c1f859e53e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "81d6d3f955d94a10a8a9563343a028a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c155ce2411e4d16b964ab60e162b45c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cc63961d65a4e05bc533f5a7c6301e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a52632c7335f4547b3ac2e5873e80780": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f62b4326bfaf4b439f5b53f0eef9e80d",
       "placeholder": "​",
       "style": "IPY_MODEL_e26c5dc8f53343b399e78f5d540eaf0d",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "a83b337e4b59457a8ac5de9174f9cf9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e26c5dc8f53343b399e78f5d540eaf0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f62b4326bfaf4b439f5b53f0eef9e80d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
