{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Fri Feb 10 14:06:35 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 28%   40C    P8     7W / 180W |  10313MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:00:05.0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Sentence Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/blog/how-to-train-sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    debug = True\n",
    "    upload_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -qqq install sentence-transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer, models, InputExample, losses\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"kaggle_lecr/data/learning-equality-curriculum-recommendations\" + \"/\"\n",
    "topics = pd.read_csv(DATA_PATH + \"topics.csv\")\n",
    "content = pd.read_csv(DATA_PATH + \"content.csv\")\n",
    "correlations = pd.read_csv(DATA_PATH + \"correlations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topics[\"title\"] = topics[\"title\"].fillna(\"No Title\")\n",
    "content[\"title\"] = content[\"title\"].fillna(\"No Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_11a1dc0bfb99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_0008768bdee6</td>\n",
       "      <td>c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_id                                        content_ids\n",
       "0  t_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...\n",
       "1  t_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...\n",
       "2  t_00069b63a70a                                     c_11a1dc0bfb99\n",
       "3  t_0006d41a73a8  c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...\n",
       "4  t_0008768bdee6       c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"kaggle_lecr/data/uns_data/train_lecr_uns_top_n_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_topic_ids_content_ids = train.groupby(\"topics_ids\")[\"content_ids\"].apply(set).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations[\"content_ids\"] = correlations[\"content_ids\"].apply(lambda x: set(x.split()))\n",
    "corr_topic_ids_content_ids = correlations.set_index(\"topic_id\")\n",
    "corr_topic_ids_content_ids = corr_topic_ids_content_ids.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics_ids\n",
       "t_00004da3a1b2    {c_0b4a3ea959ba, c_48c2aa56909a, c_a6029b48a44...\n",
       "t_00068291e9a4    {c_b228ae247379, c_88f804268f39, c_035baf9425e...\n",
       "t_00069b63a70a    {c_c25696bc9352, c_f99c320132eb, c_362366142e3...\n",
       "t_0006d41a73a8    {c_0263cb12601d, c_e2d33adb1c78, c_9cb25047417...\n",
       "t_0008768bdee6    {c_a3c74443d8d3, c_91c6c2b32396, c_bf882e1890d...\n",
       "Name: content_ids, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_topic_ids_content_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_00004da3a1b2</th>\n",
       "      <td>{c_1108dd0c7a5d, c_376c5a8eb028, c_5bc0e1e2cba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_00068291e9a4</th>\n",
       "      <td>{c_ebb7fdf10a7e, c_89ce9367be10, c_ac1672cdcd2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_00069b63a70a</th>\n",
       "      <td>{c_11a1dc0bfb99}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_0006d41a73a8</th>\n",
       "      <td>{c_5e375cf14c47, c_b972646631cb, c_d7a0d7eaf79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_0008768bdee6</th>\n",
       "      <td>{c_7d1a964d66d5, c_aab93ee667f4, c_34e1424229b4}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      content_ids\n",
       "topic_id                                                         \n",
       "t_00004da3a1b2  {c_1108dd0c7a5d, c_376c5a8eb028, c_5bc0e1e2cba...\n",
       "t_00068291e9a4  {c_ebb7fdf10a7e, c_89ce9367be10, c_ac1672cdcd2...\n",
       "t_00069b63a70a                                   {c_11a1dc0bfb99}\n",
       "t_0006d41a73a8  {c_5e375cf14c47, c_b972646631cb, c_d7a0d7eaf79...\n",
       "t_0008768bdee6   {c_7d1a964d66d5, c_aab93ee667f4, c_34e1424229b4}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_topic_ids_content_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4769cc905230497292b526ee6bdf911c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_id = {}\n",
    "for topic_id, train_content_id, corr_content_id in tqdm(\n",
    "    zip(train_topic_ids_content_ids.index, train_topic_ids_content_ids, corr_topic_ids_content_ids[\"content_ids\"]),\n",
    "    total=len(train_topic_ids_content_ids)\n",
    "):\n",
    "    pos = corr_content_id\n",
    "    neg = train_content_id - corr_content_id\n",
    "    output_id[topic_id] = {\"pos\": pos, \"neg\": neg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5664bc2981458ab6bbde7f272994fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_list = []\n",
    "for topic_id in tqdm(output_id.keys()):\n",
    "    topic_title = topics.loc[(topics[\"id\"] == topic_id), \"title\"].values[0]\n",
    "    pos_content_ids = output_id[topic_id][\"pos\"]\n",
    "    neg_content_ids = output_id[topic_id][\"neg\"]\n",
    "    \n",
    "    pos_content_titles = content.loc[(content[\"id\"].isin(list(pos_content_ids))),\"title\"].tolist()\n",
    "    neg_content_titles = content.loc[(content[\"id\"].isin(list(neg_content_ids))),\"title\"].tolist()\n",
    "    output_list.append([{\"query\": topic_title,\"pos\": pos_content_titles, \"neg\": neg_content_titles}])\n",
    "    if CFG.debug and len(output_list) == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.DataFrame(output_list, columns=[\"set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745fd25f38614ac9866574a0c179d1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "train_examples = []\n",
    "train_data = df_dataset['set']\n",
    "n_examples = df_dataset.shape[0]\n",
    "\n",
    "cnt = 0\n",
    "for i in tqdm(range(n_examples), total=n_examples):\n",
    "    example = train_data[i]\n",
    "    for query, pos, neg in itertools.product([example['query']], example['pos'], example['neg'][:10]):\n",
    "        train_examples.append(InputExample(texts=[query, pos, neg]))\n",
    "        cnt += 1\n",
    "    if CFG.debug and cnt >= 100:\n",
    "        break\n",
    "    elif cnt >= 100_000: # positive sampleのみだと6万ぐらいであり、上回るように\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dd23d4ec824ec3a4c7aa60ed9736e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbcd885f92d4527b981bcd3d7d5e4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd2219a3504429196a2ba2bc7538b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a709ef3e085475db012188b4b08d565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000c037b3bdb4ee3857ef17fe62dfd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1849b545300445369c2d3f6367c59696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f77adc577d14d8c9d6d81c120a640ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985b6eba27bd42a1bfb2510e25b1f36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0291063b3746dda1a46fcd30bb15c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0431d19b0f4bdca7d959bd9b13f7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67db24cf67814df0a948db1060fd2b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/402 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7356baa61c8c4acaa0c21b149f1ffb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_id = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "train_loss = losses.TripletLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559ea03c8318412e83252d6dc8f3357b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ff132862a040f7a14b5f34a09b402c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "if CFG.debug:\n",
    "    num_epochs = 1\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data\n",
    "    \n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finetuning-mpnet-tripletloss-100000'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipynb_path\n",
    "import re\n",
    "\n",
    "NOTEBOOK_NAME = ipynb_path.get().split(\"/\")[-1].split(\".\")[0]\n",
    "NOTEBOOK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kaggle_lecr/output/finetuning-mpnet-tripletloss-100/'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR = f\"kaggle_lecr/output/{NOTEBOOK_NAME}/\"\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.10)\n",
      "Requirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: python-slugify in /usr/lib/python3/dist-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.64.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset name:finetuning-mpnet-tripletloss-10, output_dir:kaggle_lecr/output/finetuning-mpnet-tripletloss-100/\n",
      "Starting upload for file pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.04G/1.04G [00:20<00:00, 53.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: pytorch_model.bin (1GB)\n",
      "Starting upload for file sentencepiece.bpe.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.83M/4.83M [00:00<00:00, 7.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: sentencepiece.bpe.model (5MB)\n",
      "Starting upload for file README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.70k/3.70k [00:00<00:00, 7.63kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: README.md (4KB)\n",
      "Starting upload for file tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16.3M/16.3M [00:00<00:00, 18.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tokenizer.json (16MB)\n",
      "Starting upload for file 1_Pooling.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10.0k/10.0k [00:00<00:00, 21.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: 1_Pooling.tar (10KB)\n",
      "Starting upload for file config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 821/821 [00:00<00:00, 1.18kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: config.json (821B)\n",
      "Starting upload for file modules.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:00<00:00, 346B/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: modules.json (229B)\n",
      "Starting upload for file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 536/536 [00:00<00:00, 1.17kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tokenizer_config.json (536B)\n",
      "Starting upload for file config_sentence_transformers.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 249B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: config_sentence_transformers.json (122B)\n",
      "Starting upload for file sentence_bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53.0/53.0 [00:00<00:00, 103B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: sentence_bert_config.json (53B)\n",
      "Starting upload for file special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:00<00:00, 332B/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: special_tokens_map.json (280B)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import json\n",
    "\n",
    "os.system('pip install kaggle')\n",
    "\n",
    "def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "    if \"_\" in dataset_name:\n",
    "        raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'sinchir0/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n",
    "\n",
    "if CFG.upload_data:\n",
    "    print(f\"Create Dataset name:{NOTEBOOK_NAME}, output_dir:{OUTPUT_DIR}\")\n",
    "    dataset_create_new(dataset_name=NOTEBOOK_NAME, upload_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
