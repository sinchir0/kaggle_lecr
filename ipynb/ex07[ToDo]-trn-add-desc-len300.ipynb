{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2b29e0-150c-47b3-9f56-e0241255ca87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"ex07-trn-add-desc-len300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd0b75a-2889-48af-b1df-a47cb38584bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OUTPUT_DIR = f\"/notebooks/kaggle_lecr/output/{NOTEBOOK_NAME}\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea3d0df-f4e8-4202-a89b-f5926005aa42",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch==1.12.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (1.12.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.9/site-packages (from torch==1.12.0) (4.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers==0.12.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.12.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.20.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (4.20.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from transformers==4.20.1) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.20.1) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2022.9.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip3 install torch==1.12.0 --extra-index-url https://download.pytorch.org/whl/cu116\")\n",
    "os.system(\"pip install tokenizers==0.12.1\")\n",
    "os.system(\"pip install transformers==4.20.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09c789d-506f-4886-b7ee-c222198479fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 28 00:00:55 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   41C    P8    23W / 230W |   6400MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6819dc6-ff40-4f79-8685-02db3c6a8f77",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('pip install python-dotenv')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95534da-f206-4f29-a023-0b49a499bdf9",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.2.1\n",
      "  Downloading scikit_learn-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.6/9.6 MB 83.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn==1.2.1) (1.23.4)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "Successfully installed scikit-learn-1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install scikit-learn==1.2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af13c3b",
   "metadata": {
    "papermill": {
     "duration": 7.561173,
     "end_time": "2023-02-11T02:05:08.553027",
     "exception": false,
     "start_time": "2023-02-11T02:05:00.991854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# Libraries\n",
    "# =========================================================================================\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f108c3d",
   "metadata": {
    "papermill": {
     "duration": 0.01567,
     "end_time": "2023-02-11T02:05:08.574968",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.559298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Configurations\n",
    "# =========================================================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    upload_data = True\n",
    "    wandb = True\n",
    "    print_freq = 500\n",
    "    num_workers = 4\n",
    "    model = \"xlm-roberta-base\"\n",
    "    gradient_checkpointing = False\n",
    "    num_cycles = 0.5\n",
    "    warmup_ratio = 0.1\n",
    "    encoder_lr = 1e-5\n",
    "    decoder_lr = 1e-4\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    batch_size = 368# 32#128#64#32\n",
    "    weight_decay = 0.01\n",
    "    max_grad_norm = 0.012\n",
    "    max_len = 512\n",
    "    n_folds = 5\n",
    "    seed = 42\n",
    "    epochs = 5\n",
    "    data_url = \"/notebooks/kaggle_lecr/data/learning-equality-curriculum-recommendations\"\n",
    "    train_set_url = \"/notebooks/kaggle_lecr/output/ex07-uns-add-desc-len100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf556033-94aa-4878-9379-1cd79a7bc14d",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb==0.13.3\n",
      "  Downloading wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 33.2 MB/s eta 0:00:00\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (6.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (60.10.0)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 30.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (1.16.0)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (5.9.3)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 36.2 MB/s eta 0:00:00\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (3.20.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (2.28.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from wandb==0.13.3) (8.1.3)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 19.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb==0.13.3) (1.26.11)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: promise, pathtools\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=a31a25eb423d37784bcbab73ef82da047868d2cdf24081fc11765a4bfa7c09dd\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/ee/8d/57af0d8b0d34c2e918ff29d3af02b348db6499bb107caa007e\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=ca229019c1ef2280189d5f13f8df42e8e14b9e99c7debc1042bbeee3ad62e014\n",
      "  Stored in directory: /root/.cache/pip/wheels/20/7c/09/4ad42725a29fce4bc21137c7f25f062b3655a4aea5b0e8d9a2\n",
      "Successfully built promise pathtools\n",
      "Installing collected packages: pathtools, smmap, shortuuid, setproctitle, sentry-sdk, promise, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 promise-2.3 sentry-sdk-1.16.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinchir0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/kaggle_lecr/ipynb/wandb/run-20230228_000115-txajn9p4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sinchir0/LECR/runs/txajn9p4\" target=\"_blank\">ex07-trn-add-desc-len300</a></strong> to <a href=\"https://wandb.ai/sinchir0/LECR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "if CFG.wandb:\n",
    "    os.system('pip install wandb==0.13.3')\n",
    "    import wandb\n",
    "\n",
    "    try:\n",
    "        # for kaggle\n",
    "        # from kaggle_secrets import UserSecretsClient\n",
    "        # user_secrets = UserSecretsClient()\n",
    "        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "        \n",
    "        # for paperspace\n",
    "        secret_value_0 = os.getenv('WANDB_API_KEY')\n",
    "        wandb.login(key=secret_value_0)\n",
    "        \n",
    "        anony = None\n",
    "    except:\n",
    "        anony = \"must\"\n",
    "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "\n",
    "    def class2dict(f):\n",
    "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "    run = wandb.init(project='LECR',\n",
    "                     entity=\"sinchir0\",\n",
    "                     name=NOTEBOOK_NAME,\n",
    "                     config=class2dict(CFG),\n",
    "                     group=\"trn\",\n",
    "                     job_type=\"train\",\n",
    "                     anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea8f99c",
   "metadata": {
    "papermill": {
     "duration": 0.014544,
     "end_time": "2023-02-11T02:05:08.595307",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.580763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Seed everything for deterministic results\n",
    "# =========================================================================================\n",
    "def seed_everything(cfg):\n",
    "    random.seed(cfg.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    torch.cuda.manual_seed(cfg.seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd14795",
   "metadata": {
    "papermill": {
     "duration": 0.015773,
     "end_time": "2023-02-11T02:05:08.616987",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.601214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Data Loading\n",
    "# =========================================================================================\n",
    "def read_data(cfg):\n",
    "    # train = pd.read_csv(f\"{cfg.train_set_url}/train.csv\")\n",
    "    train = pd.read_pickle(f\"{cfg.train_set_url}/train.pkl\")\n",
    "    \n",
    "    topics = pd.read_csv(cfg.data_url + \"/\" + \"topics.csv\")\n",
    "    content = pd.read_csv(cfg.data_url + \"/\" + \"content.csv\")\n",
    "    correlations = pd.read_csv(cfg.data_url + \"/\" + \"correlations.csv\")\n",
    "\n",
    "    topics[\"title\"] = topics[\"title\"].fillna(\"\")\n",
    "    content[\"title\"] = content[\"title\"].fillna(\"\")\n",
    "    \n",
    "    topics[\"description\"] = topics[\"description\"].fillna(\"\")\n",
    "    content[\"description\"] = content[\"description\"].fillna(\"\")\n",
    "    \n",
    "    content['text'] = content['text'].fillna(\"\")\n",
    "    \n",
    "    print(' ')\n",
    "    print('-' * 50)\n",
    "    print(f\"train.shape: {train.shape}\")\n",
    "    print(f\"correlations.shape: {correlations.shape}\")\n",
    "    return train, topics, content, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c94a6b",
   "metadata": {
    "papermill": {
     "duration": 0.013152,
     "end_time": "2023-02-11T02:05:08.635842",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.622690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(train: pd.DataFrame):\n",
    "    # Create feature column\n",
    "    # train['text'] = train['topics_titles'] + '[SEP]' + train['content_titles']\n",
    "    train['text'] = train['topics_texts'] + '[SEP]' + train['content_texts']\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d457e372",
   "metadata": {
    "papermill": {
     "duration": 0.017013,
     "end_time": "2023-02-11T02:05:08.658444",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.641431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_cat_info(train: pd.DataFrame, topics: pd.DataFrame, content:pd.DataFrame):\n",
    "    merge_train = pd.merge(train, topics[[\"id\", \"level\", \"category\"]], left_on=\"topics_ids\", right_on=\"id\", how=\"left\")\n",
    "    merge_train = merge_train.drop(\"id\", axis=1)\n",
    "    merge_train = pd.merge(merge_train, content[[\"id\", \"kind\"]], left_on=\"content_ids\", right_on=\"id\", how=\"left\")\n",
    "    merge_train = merge_train.drop(\"id\", axis=1)\n",
    "    \n",
    "    merge_train[\"level_tag\"] = merge_train[\"level\"].apply(lambda x: f\"[LEVEL{x}]\")\n",
    "    merge_train[\"category_tag\"] = merge_train[\"category\"].apply(lambda x: f\"[CATEGORY_{x.upper()}]\")\n",
    "    merge_train[\"kind_tag\"] = merge_train[\"kind\"].apply(lambda x: f\"[KIND_{x.upper()}]\")\n",
    "    \n",
    "    level_tag_list = sorted(merge_train[\"level_tag\"].unique()) \n",
    "    category_list = sorted(merge_train[\"category_tag\"].unique()) \n",
    "    kind_list = sorted(merge_train[\"kind_tag\"].unique()) \n",
    "    \n",
    "    # train['topics_titles'] = merge_train['level_tag'] + merge_train[\"category_tag\"] + merge_train['topics_titles'] \n",
    "    train['topics_texts'] = merge_train['level_tag'] + merge_train[\"category_tag\"] + merge_train['topics_texts'] \n",
    "    # train['content_titles'] = merge_train['kind_tag'] + merge_train['content_titles']\n",
    "    train['content_texts'] = merge_train['kind_tag'] + merge_train['content_texts']\n",
    "    \n",
    "    return train, level_tag_list, category_list, kind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a68033ec",
   "metadata": {
    "papermill": {
     "duration": 0.01453,
     "end_time": "2023-02-11T02:05:08.678562",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.664032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# CV split\n",
    "# =========================================================================================\n",
    "def cv_split(train, cfg):\n",
    "    kfold = StratifiedGroupKFold(n_splits = cfg.n_folds, shuffle = True, random_state = cfg.seed)\n",
    "    for num, (train_index, val_index) in enumerate(kfold.split(train, train['target'], train['topics_ids'])):\n",
    "        train.loc[val_index, 'fold'] = int(num)\n",
    "    train['fold'] = train['fold'].astype(int)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7007386",
   "metadata": {
    "papermill": {
     "duration": 0.016546,
     "end_time": "2023-02-11T02:05:08.702048",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.685502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# F2 score metric\n",
    "# =========================================================================================\n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f2 = tp / (tp + 0.2 * fp + 0.8 * fn)\n",
    "    return round(f2.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79f24de",
   "metadata": {
    "papermill": {
     "duration": 0.015781,
     "end_time": "2023-02-11T02:05:08.723530",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.707749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Get max length\n",
    "# =========================================================================================\n",
    "def get_max_length(train, cfg):\n",
    "    lengths = []\n",
    "    for text in tqdm(train['text'].fillna(\"\").values, total = len(train)):\n",
    "        length = len(cfg.tokenizer(text, add_special_tokens = False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "    cfg.max_len = min(max(lengths) + 5, cfg.max_len) # cls + sep + level + category + kind\n",
    "    print(f\"max_len: {cfg.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8d29cf",
   "metadata": {
    "papermill": {
     "duration": 0.058232,
     "end_time": "2023-02-11T02:05:08.787596",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.729364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Prepare input, tokenize\n",
    "# =========================================================================================\n",
    "def prepare_input(text, cfg):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "        max_length = cfg.max_len,\n",
    "        pad_to_max_length = True,\n",
    "        truncation = True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Custom dataset\n",
    "# =========================================================================================\n",
    "class custom_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "        self.labels = df['target'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item], self.cfg)\n",
    "        label = torch.tensor(self.labels[item], dtype = torch.float)\n",
    "        return inputs, label\n",
    "    \n",
    "# =========================================================================================\n",
    "# Collate function for training\n",
    "# =========================================================================================\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Mean pooling class\n",
    "# =========================================================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "# =========================================================================================\n",
    "# Model\n",
    "# =========================================================================================\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states = True)\n",
    "        self.config.hidden_dropout = 0.0\n",
    "        self.config.hidden_dropout_prob = 0.0\n",
    "        self.config.attention_dropout = 0.0\n",
    "        self.config.attention_probs_dropout_prob = 0.0\n",
    "        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n",
    "        # AutoTokenizer.from_pretrainedでadditional_special_tokensをした際は、増えたtoken分、新しい語彙として登録が必要らしい\n",
    "        # https://cocoinit23.com/pytorch-runtimeerror-cuda-error-device-side-assert-triggered/\n",
    "        self.model.resize_token_embeddings(len(cfg.tokenizer))\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "    \n",
    "# =========================================================================================\n",
    "# Helper functions\n",
    "# =========================================================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "# =========================================================================================\n",
    "# Train function loop\n",
    "# =========================================================================================\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled = True)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, target) in enumerate(train_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled = True):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch + 1, \n",
    "                          step, \n",
    "                          len(train_loader), \n",
    "                          remain = timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                          loss = losses,\n",
    "                          grad_norm = grad_norm,\n",
    "                          lr = scheduler.get_lr()[0]))\n",
    "    return losses.avg\n",
    "\n",
    "# =========================================================================================\n",
    "# Valid function loop\n",
    "# =========================================================================================\n",
    "def valid_fn(valid_loader, model, criterion, device, cfg):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, target) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().squeeze().to('cpu').numpy().reshape(-1))\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, \n",
    "                          len(valid_loader),\n",
    "                          loss = losses,\n",
    "                          remain = timeSince(start, float(step + 1) / len(valid_loader))))\n",
    "    predictions = np.concatenate(preds, axis = 0)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "# =========================================================================================\n",
    "# Get best threshold\n",
    "# =========================================================================================\n",
    "def get_best_threshold(x_val, val_predictions, correlations):\n",
    "    best_score = 0\n",
    "    best_threshold = None\n",
    "    for thres in np.arange(0.001, 0.1, 0.001):\n",
    "        x_val['predictions'] = np.where(val_predictions > thres, 1, 0)\n",
    "        x_val1 = x_val[x_val['predictions'] == 1]\n",
    "        x_val1 = x_val1.groupby(['topics_ids'])['content_ids'].unique().reset_index()\n",
    "        x_val1['content_ids'] = x_val1['content_ids'].apply(lambda x: ' '.join(x))\n",
    "        x_val1.columns = ['topic_id', 'predictions']\n",
    "        x_val0 = pd.Series(x_val['topics_ids'].unique())\n",
    "        x_val0 = x_val0[~x_val0.isin(x_val1['topic_id'])]\n",
    "        x_val0 = pd.DataFrame({'topic_id': x_val0.values, 'predictions': \"\"})\n",
    "        x_val_r = pd.concat([x_val1, x_val0], axis = 0, ignore_index = True)\n",
    "        x_val_r = x_val_r.merge(correlations, how = 'left', on = 'topic_id')\n",
    "        score = f2_score(x_val_r['content_ids'], x_val_r['predictions'])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = thres\n",
    "    return best_score, best_threshold\n",
    "    \n",
    "# =========================================================================================\n",
    "# Train & Evaluate\n",
    "# =========================================================================================\n",
    "def train_and_evaluate_one_fold(train, correlations, fold, cfg, add_topic_content: list):\n",
    "    # 高速化、計算の再現性は担保されない、https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    print(' ')\n",
    "    print(f\"========== fold: {fold} training ==========\")\n",
    "    # Split train & validation\n",
    "    x_train = train[train['fold'] != fold]\n",
    "    x_val = train[train['fold'] == fold]\n",
    "    \n",
    "    # categoryがsourceのtopicは評価に使わない\n",
    "    x_val = x_val[~x_val[\"topics_texts\"].str.contains(\"CATEGORY_SOURCE\")]\n",
    "    \n",
    "    # 追加したpositiveのtopic, contentは評価には使わない\n",
    "    x_val = x_val[~(x_val[\"topics_ids\"] + x_val[\"content_ids\"]).isin(add_topic_content)]\n",
    "    \n",
    "    valid_labels = x_val['target'].values\n",
    "    train_dataset = custom_dataset(x_train, cfg)\n",
    "    valid_dataset = custom_dataset(x_val, cfg)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = True, \n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "    # Get model\n",
    "    model = custom_model(cfg)\n",
    "    model.to(device)\n",
    "    # Optimizer\n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay = 0.0):\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "            'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "    optimizer_parameters = get_optimizer_params(\n",
    "        model, \n",
    "        encoder_lr = cfg.encoder_lr, \n",
    "        decoder_lr = cfg.decoder_lr,\n",
    "        weight_decay = cfg.weight_decay\n",
    "    )\n",
    "    optimizer = AdamW(\n",
    "        optimizer_parameters, \n",
    "        lr = cfg.encoder_lr, \n",
    "        eps = cfg.eps, \n",
    "        betas = cfg.betas\n",
    "    )\n",
    "    num_train_steps = int(len(x_train) / cfg.batch_size * cfg.epochs)\n",
    "    num_warmup_steps = num_train_steps * cfg.warmup_ratio\n",
    "    # Scheduler\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps = num_warmup_steps, \n",
    "        num_training_steps = num_train_steps, \n",
    "        num_cycles = cfg.num_cycles\n",
    "        )\n",
    "    # Training & Validation loop\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "    best_score = 0\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        start_time = time.time()\n",
    "        # Train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg)\n",
    "        # Validation\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device, cfg)\n",
    "        # Compute f2_score\n",
    "        score, threshold = get_best_threshold(x_val, predictions, correlations)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        print(f'Epoch {epoch+1} - Score: {score:.4f} - Threshold: {threshold:.5f}')\n",
    "        torch.save(\n",
    "            {'model': model.state_dict(), 'predictions': predictions}, \n",
    "            f\"{OUTPUT_DIR}/{cfg.model.replace('/', '-')}_fold{fold}_{cfg.seed}_epoch{epoch}.pth\"\n",
    "        )\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save(\n",
    "                {'model': model.state_dict(), 'predictions': predictions}, \n",
    "                f\"{OUTPUT_DIR}/{cfg.model.replace('/', '-')}_fold{fold}_{cfg.seed}_best_model.pth\"\n",
    "                )\n",
    "            val_predictions = predictions\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    # Get best threshold\n",
    "    best_score, best_threshold = get_best_threshold(x_val, val_predictions, correlations)\n",
    "    # Save Score, Threshold\n",
    "    score = {\"best_score\": best_score, \"best_threshold\": best_threshold}\n",
    "    with open(f\"{OUTPUT_DIR}/score.pkl\", \"wb\") as f:\n",
    "        pickle.dump(score, f)\n",
    "    print(f'Our CV score is {best_score} using a threshold of {best_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3f57c04",
   "metadata": {
    "papermill": {
     "duration": 0.019865,
     "end_time": "2023-02-11T02:05:08.813594",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.793729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed everything\n",
    "seed_everything(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75b78f49",
   "metadata": {
    "papermill": {
     "duration": 22.091749,
     "end_time": "2023-02-11T02:05:30.911554",
     "exception": false,
     "start_time": "2023-02-11T02:05:08.819805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "train.shape: (615170, 5)\n",
      "correlations.shape: (61517, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train, topics, content, correlations = read_data(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a72c73ae-6a03-4db9-8f7f-eba633295b17",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics_ids       0\n",
       "content_ids      0\n",
       "topics_texts     0\n",
       "content_texts    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0e6c17a-1e04-43e3-8522-645a7e50d555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# positive sampleを足す\n",
    "def add_positive_sample(train: pd.DataFrame, correlations: pd.DataFrame, topics: pd.DataFrame, content: pd.DataFrame):\n",
    "    \n",
    "    topic_text_dict = dict(zip(topics[\"id\"], topics['title'] + \" \" + topics['description']))\n",
    "    content_text_dict = dict(zip(content[\"id\"], content['title'] + \" \" + content['description']))\n",
    "    \n",
    "    correlations[\"content_ids_list\"] = correlations[\"content_ids\"].apply(lambda x : x.split())\n",
    "    \n",
    "    all_positive_sample = correlations.explode(\"content_ids_list\")[[\"topic_id\",\"content_ids_list\"]]\n",
    "    all_positive_sample = all_positive_sample.rename(columns={\"topic_id\":\"topics_ids\",\"content_ids_list\":\"content_ids\"})\n",
    "    \n",
    "    all_positive_sample[\"topics_texts\"] = all_positive_sample[\"topics_ids\"].map(topic_text_dict)\n",
    "    all_positive_sample[\"content_texts\"] = all_positive_sample[\"content_ids\"].map(content_text_dict)\n",
    "    all_positive_sample[\"target\"] = 1\n",
    "    \n",
    "    all_positive_sample = all_positive_sample.reset_index(drop=True)\n",
    "    \n",
    "    # 追加するtopic, contentのみを持つlistを生成\n",
    "    all_positive_topic_content = (all_positive_sample[\"topics_ids\"] + all_positive_sample[\"content_ids\"]).tolist()\n",
    "    train_positive = train[train[\"target\"] == 1]\n",
    "    train_positive_topic_content = (train_positive[\"topics_ids\"] + train_positive[\"content_ids\"]).tolist()\n",
    "    add_topic_content = list(set(all_positive_topic_content) - set(train_positive_topic_content))\n",
    "    \n",
    "    # trainにpositive sampleを追加\n",
    "    train = pd.concat([train, all_positive_sample]).drop_duplicates(subset=[\"topics_ids\",\"content_ids\"], keep='first')\n",
    "    train = train.sort_values(\"topics_ids\")\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    return train, add_topic_content\n",
    "\n",
    "train, add_topic_content = add_positive_sample(train, correlations, topics, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67fa349b-7b57-43d6-844e-533dbbeced8a",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"topics_texts\"] = train[\"topics_texts\"].apply(lambda x: x[:300])\n",
    "train[\"content_texts\"] = train[\"content_texts\"].apply(lambda x: x[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cacb8ef-7b40-44a8-9923-e811d089ff1c",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122657"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(add_topic_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27837264",
   "metadata": {
    "papermill": {
     "duration": 0.02252,
     "end_time": "2023-02-11T02:05:30.947474",
     "exception": false,
     "start_time": "2023-02-11T02:05:30.924954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train[:1000]\n",
    "    CFG.epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4205a7c0",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.095627,
     "end_time": "2023-02-11T02:05:33.051735",
     "exception": false,
     "start_time": "2023-02-11T02:05:30.956108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, level_tag_list, category_list, kind_list = merge_cat_info(train, topics, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb705e19",
   "metadata": {
    "papermill": {
     "duration": 0.227458,
     "end_time": "2023-02-11T02:05:33.352932",
     "exception": false,
     "start_time": "2023-02-11T02:05:33.125474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09133fac",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.251238,
     "end_time": "2023-02-11T02:05:41.664455",
     "exception": false,
     "start_time": "2023-02-11T02:05:33.413217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af57a7bcb7184c8ab8250a829dd52ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba953e284f2406da8c9cb81b162d0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1d34c4dafa4582a8c34d561461951e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "CFG.tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model,\n",
    "    additional_special_tokens = level_tag_list + category_list + kind_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc3017c7",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018461,
     "end_time": "2023-02-11T02:05:41.691787",
     "exception": false,
     "start_time": "2023-02-11T02:05:41.673326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[LEVEL0]',\n",
       " '[LEVEL10]',\n",
       " '[LEVEL1]',\n",
       " '[LEVEL2]',\n",
       " '[LEVEL3]',\n",
       " '[LEVEL4]',\n",
       " '[LEVEL5]',\n",
       " '[LEVEL6]',\n",
       " '[LEVEL7]',\n",
       " '[LEVEL8]',\n",
       " '[LEVEL9]',\n",
       " '[CATEGORY_ALIGNED]',\n",
       " '[CATEGORY_SOURCE]',\n",
       " '[CATEGORY_SUPPLEMENTAL]',\n",
       " '[KIND_AUDIO]',\n",
       " '[KIND_DOCUMENT]',\n",
       " '[KIND_EXERCISE]',\n",
       " '[KIND_HTML5]',\n",
       " '[KIND_VIDEO]']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.tokenizer.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b490a510-9e68-4203-b3a1-9bd5ce3c787a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# categoryがsourceのnegativeデータを減らし、計算時間を短くする\n",
    "# train[\"is_category_source\"] = train[\"topics_texts\"].str.contains(\"CATEGORY_SOURCE\")\n",
    "# train = train[~(train[\"is_category_source\"] & (train[\"target\"] == 0))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4871bf1d-8673-4cec-8472-7daa58e3e865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 計算を終わらせるため、行を減らす\n",
    "# if not CFG.debug:\n",
    "#     train = train.sample(200000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e5a3ce5",
   "metadata": {
    "papermill": {
     "duration": 24.616901,
     "end_time": "2023-02-11T02:06:06.316153",
     "exception": false,
     "start_time": "2023-02-11T02:05:41.699252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CV split\n",
    "train = cv_split(train, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "234ea5e9-9f5c-4e84-a884-de3ab5d0cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = train[[\"topics_ids\",\"fold\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be63cf4e-0915-42ed-b32b-9adf32adb3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.drop_duplicates().to_csv(\"topics_ids_fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb66dca3-cbb8-4d3e-a012-eb589fc18c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_list = train[train[\"fold\"] == 0][\"topics_ids\"].unique().tolist()\n",
    "with open(f\"{OUTPUT_DIR}/fold_0_topics_ids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fold0_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "287e8991-6d5a-470d-9459-2cc95718db13",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    148043\n",
      "1    147968\n",
      "0    147584\n",
      "2    147397\n",
      "4    146835\n",
      "Name: fold, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"fold\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "494577d4-2513-465c-938c-c4d635829e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84d901da-9881-4008-8a1d-53655a9722ec",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    457908\n",
       "1    279919\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07e9b843",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 81.097871,
     "end_time": "2023-02-11T02:07:27.589260",
     "exception": false,
     "start_time": "2023-02-11T02:06:06.491389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4112cfd36eb471cbb1b683befab987b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/737827 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len: 253\n"
     ]
    }
   ],
   "source": [
    "# Get max length\n",
    "get_max_length(train, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "896807cf-cf68-42f9-aca1-118b255065e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5253160",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 17391.060041,
     "end_time": "2023-02-11T06:57:18.656824",
     "exception": false,
     "start_time": "2023-02-11T02:07:27.596783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1603] Elapsed 0m 2s (remain 58m 42s) Loss: 0.7549(0.7549) Grad: inf  LR: 0.00000001  \n",
      "Epoch: [1][500/1603] Elapsed 3m 36s (remain 7m 56s) Loss: 0.4606(0.5887) Grad: 5.7117  LR: 0.00000625  \n",
      "Epoch 1 - avg_train_loss: 0.4337  avg_val_loss: 0.3842  time: 796s\n",
      "Epoch 1 - Score: 0.4167 - Threshold: 0.09900\n",
      "Epoch 1 - Save Best Score: 0.4167 Model\n",
      "Epoch: [2][0/1603] Elapsed 0m 0s (remain 25m 41s) Loss: 0.3114(0.3114) Grad: 4.4783  LR: 0.00000970  \n",
      "Epoch: [2][1500/1603] Elapsed 10m 43s (remain 0m 43s) Loss: 0.3264(0.3194) Grad: 5.4884  LR: 0.00000769  \n",
      "Epoch: [2][1602/1603] Elapsed 11m 26s (remain 0m 0s) Loss: 0.3113(0.3186) Grad: 3.8017  LR: 0.00000750  \n",
      "EVAL: [0/135] Elapsed 0m 1s (remain 2m 27s) Loss: 0.3031(0.3031) \n",
      "EVAL: [134/135] Elapsed 1m 16s (remain 0m 0s) Loss: 0.4559(0.3639) \n",
      "Epoch 2 - avg_train_loss: 0.3186  avg_val_loss: 0.3639  time: 792s\n",
      "Epoch 2 - Score: 0.4298 - Threshold: 0.07800\n",
      "Epoch 2 - Save Best Score: 0.4298 Model\n",
      "Epoch: [3][0/1603] Elapsed 0m 0s (remain 26m 19s) Loss: 0.2691(0.2691) Grad: 4.0423  LR: 0.00000750  \n",
      "Epoch: [3][500/1603] Elapsed 3m 33s (remain 7m 50s) Loss: 0.2798(0.2879) Grad: 3.2650  LR: 0.00000651  \n",
      "Epoch: [3][1000/1603] Elapsed 7m 7s (remain 4m 16s) Loss: 0.2340(0.2853) Grad: 4.7742  LR: 0.00000544  \n",
      "Epoch: [3][1500/1603] Elapsed 10m 42s (remain 0m 43s) Loss: 0.3980(0.2843) Grad: 6.2056  LR: 0.00000436  \n",
      "Epoch: [3][1602/1603] Elapsed 11m 26s (remain 0m 0s) Loss: 0.2497(0.2840) Grad: 5.0729  LR: 0.00000414  \n",
      "EVAL: [0/135] Elapsed 0m 1s (remain 2m 21s) Loss: 0.2857(0.2857) \n",
      "EVAL: [134/135] Elapsed 1m 16s (remain 0m 0s) Loss: 0.4686(0.3564) \n",
      "Epoch 3 - avg_train_loss: 0.2840  avg_val_loss: 0.3564  time: 792s\n",
      "Epoch 3 - Score: 0.4388 - Threshold: 0.06700\n",
      "Epoch 3 - Save Best Score: 0.4388 Model\n",
      "Epoch: [4][0/1603] Elapsed 0m 1s (remain 28m 18s) Loss: 0.2860(0.2860) Grad: 5.3910  LR: 0.00000413  \n",
      "Epoch: [4][500/1603] Elapsed 3m 34s (remain 7m 52s) Loss: 0.2713(0.2587) Grad: 5.1398  LR: 0.00000309  \n",
      "Epoch: [4][1000/1603] Elapsed 7m 8s (remain 4m 17s) Loss: 0.2208(0.2574) Grad: 6.3070  LR: 0.00000214  \n",
      "Epoch: [4][1500/1603] Elapsed 10m 41s (remain 0m 43s) Loss: 0.2383(0.2566) Grad: 4.8480  LR: 0.00000132  \n",
      "Epoch: [4][1602/1603] Elapsed 11m 26s (remain 0m 0s) Loss: 0.2515(0.2564) Grad: 5.6410  LR: 0.00000117  \n",
      "EVAL: [0/135] Elapsed 0m 1s (remain 2m 21s) Loss: 0.2893(0.2893) \n",
      "EVAL: [134/135] Elapsed 1m 16s (remain 0m 0s) Loss: 0.4923(0.3544) \n",
      "Epoch 4 - avg_train_loss: 0.2564  avg_val_loss: 0.3544  time: 792s\n",
      "Epoch 4 - Score: 0.4433 - Threshold: 0.06000\n",
      "Epoch 4 - Save Best Score: 0.4433 Model\n",
      "Epoch: [5][0/1603] Elapsed 0m 0s (remain 25m 32s) Loss: 0.2140(0.2140) Grad: 5.2245  LR: 0.00000117  \n",
      "Epoch: [5][500/1603] Elapsed 3m 35s (remain 7m 54s) Loss: 0.2418(0.2401) Grad: 7.8052  LR: 0.00000057  \n",
      "Epoch: [5][1000/1603] Elapsed 7m 9s (remain 4m 18s) Loss: 0.2663(0.2410) Grad: 7.8557  LR: 0.00000017  \n",
      "Epoch: [5][1500/1603] Elapsed 10m 42s (remain 0m 43s) Loss: 0.2209(0.2405) Grad: 5.8030  LR: 0.00000001  \n",
      "Epoch: [5][1602/1603] Elapsed 11m 26s (remain 0m 0s) Loss: 0.2508(0.2405) Grad: 6.5735  LR: 0.00000000  \n",
      "EVAL: [0/135] Elapsed 0m 1s (remain 2m 21s) Loss: 0.2912(0.2912) \n",
      "EVAL: [134/135] Elapsed 1m 16s (remain 0m 0s) Loss: 0.5093(0.3611) \n",
      "Epoch 5 - avg_train_loss: 0.2405  avg_val_loss: 0.3611  time: 789s\n",
      "Epoch 5 - Score: 0.4437 - Threshold: 0.04900\n",
      "Epoch 5 - Save Best Score: 0.4437 Model\n",
      "Our CV score is 0.4437 using a threshold of 0.049\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate one fold\n",
    "train_and_evaluate_one_fold(train, correlations, 0, CFG, add_topic_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f858de-30f7-455a-856f-d9b1631f087f",
   "metadata": {},
   "source": [
    "# Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "435a8cd3-0dc7-453c-b37e-e94d125fc681",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.0/59.0 kB 9.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (2022.9.24)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (4.64.1)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from kaggle) (1.26.11)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.2/78.2 kB 19.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->kaggle) (2.1.1)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73049 sha256=193fcf6ec276575b307b245eba90e0a29f584f731e64d1382e6f1ae347595ead\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/0a/6a/77a4f3a534f0e5fd0909a376bbdfc88238a43eb2ac35947dc7\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-8.0.1 text-unidecode-1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"pip install kaggle\")\n",
    "os.system(\"mkdir -p ~/.kaggle/\")\n",
    "os.system(\"cp /notebooks/kaggle_lecr/kaggle.json ~/.kaggle/\")\n",
    "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "510a516b-6edc-4aac-88c5-93f58b6ece6c",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset name:ex07-trn-add-desc-len300, output_dir:/notebooks/kaggle_lecr/output/ex07-trn-add-desc-len300\n",
      "Starting upload for file xlm-roberta-base_fold0_42_epoch2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.04G/1.04G [01:05<00:00, 17.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: xlm-roberta-base_fold0_42_epoch2.pth (1GB)\n",
      "Starting upload for file xlm-roberta-base_fold0_42_epoch4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.04G/1.04G [00:17<00:00, 63.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: xlm-roberta-base_fold0_42_epoch4.pth (1GB)\n",
      "Starting upload for file xlm-roberta-base_fold0_42_epoch3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.04G/1.04G [00:32<00:00, 33.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: xlm-roberta-base_fold0_42_epoch3.pth (1GB)\n",
      "Starting upload for file score.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [00:00<00:00, 318B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: score.pkl (169B)\n",
      "Starting upload for file xlm-roberta-base_fold0_42_epoch0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.04G/1.04G [00:50<00:00, 22.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: xlm-roberta-base_fold0_42_epoch0.pth (1GB)\n",
      "Starting upload for file fold_0_topics_ids.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204k/204k [00:00<00:00, 434kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: fold_0_topics_ids.pkl (204KB)\n",
      "Starting upload for file xlm-roberta-base_fold0_42_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.04G/1.04G [00:19<00:00, 56.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: xlm-roberta-base_fold0_42_best_model.pth (1GB)\n",
      "Starting upload for file xlm-roberta-base_fold0_42_epoch1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.04G/1.04G [00:23<00:00, 48.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: xlm-roberta-base_fold0_42_epoch1.pth (1GB)\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import json\n",
    "\n",
    "def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "    if \"_\" in dataset_name:\n",
    "        raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'sinchir0/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n",
    "\n",
    "if CFG.upload_data:\n",
    "    print(f\"Create Dataset name:{NOTEBOOK_NAME}, output_dir:{OUTPUT_DIR}\")\n",
    "    dataset_create_new(dataset_name=NOTEBOOK_NAME, upload_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fda75-46ff-44dd-9bac-ec7fb5dc0e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879017b-061f-4d99-9f49-e59ab8b2884c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17548.763501,
   "end_time": "2023-02-11T06:57:21.580304",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-11T02:04:52.816803",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "218592928185498e9d59df2150307773": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a52632c7335f4547b3ac2e5873e80780",
        "IPY_MODEL_2ddfc44c7cdf4e50b90af044edb241e7",
        "IPY_MODEL_52fc9a4bd70c4d5d83cfda3bf9c96398"
       ],
       "layout": "IPY_MODEL_a83b337e4b59457a8ac5de9174f9cf9d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2ddfc44c7cdf4e50b90af044edb241e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c155ce2411e4d16b964ab60e162b45c",
       "max": 615170,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9cc63961d65a4e05bc533f5a7c6301e6",
       "tabbable": null,
       "tooltip": null,
       "value": 615170
      }
     },
     "52fc9a4bd70c4d5d83cfda3bf9c96398": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81d6d3f955d94a10a8a9563343a028a4",
       "placeholder": "​",
       "style": "IPY_MODEL_71acb0f9429c474a93233c1f859e53e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 615170/615170 [01:21&lt;00:00, 3806.35it/s]"
      }
     },
     "71acb0f9429c474a93233c1f859e53e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "81d6d3f955d94a10a8a9563343a028a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c155ce2411e4d16b964ab60e162b45c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cc63961d65a4e05bc533f5a7c6301e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a52632c7335f4547b3ac2e5873e80780": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f62b4326bfaf4b439f5b53f0eef9e80d",
       "placeholder": "​",
       "style": "IPY_MODEL_e26c5dc8f53343b399e78f5d540eaf0d",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "a83b337e4b59457a8ac5de9174f9cf9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e26c5dc8f53343b399e78f5d540eaf0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f62b4326bfaf4b439f5b53f0eef9e80d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
